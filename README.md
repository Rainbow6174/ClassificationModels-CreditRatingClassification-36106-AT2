# ClassificationModels-36106-AT2

æˆ‘éœ€è¦å®Œæˆä¸€ä¸ªassignmentä½œä¸ºè¯„åˆ†é¡¹ç›®ï¼Œé¦–å…ˆæˆ‘å°†ç»™å‡ºé¡¹ç›®è¯„åˆ†æ ‡å‡†ï¼Œåœ¨åç»­çš„é¡¹ç›®å†…å®¹ä¸­è¯·å‚è€ƒä»¥ä¸‹è¯„åˆ†æ ‡å‡†æ¥å®Œæˆé¡¹ç›®ï¼šQuality, relevance and cleanliness of code and visualisation 20 to >17.0 Pts HD ğŸ† Completed between 90-100% of the requirements ğŸ† Code is efficient, easy to understand, and maintain ğŸ† Clearly and effectively documented code ğŸ† Code executes without errors Pertinence and quality of scientific experimentation and analytic investigation 20 to >17.0 Pts HD ğŸ† Business problem is narrowly focused and suggests how the answer will be investigated ğŸ† Hypotheses are testable and accurately stated in acceptable format ğŸ† Data analysis shows excellent understanding and identification of data anomalies and main characteristics of the data ğŸ† Uses correct and complete quantitative and/or qualitative analysis to make relevant and correct decisions ğŸ† Many aspects of evaluation are discussed and a clear conclusion is drawn, with direct reference to the purpose of the experiment Depth of discussion of ethics/privacy issues (including matters related to Indigenous people ), value, benefits, risks and recommendation for business stakeholders and final users 15 to >12.0 Pts HD ğŸ† Critical affected parties (both direct and indirect) are identified ğŸ† Solution and ethical analysis is logical and clearly presented at a level that reflects extensive reflection and insight. ğŸ† Key recommendations to achieve business objectives with strong justifications and proper references. Good relevance between your analysis and the organisational strategies Strength of justification and explanation of models selected, data transformation performed, hyperparameters selected and accuracy of results with evidence supporting claims 25 to >21.0 Pts HD ğŸ† Excellent problem/opportunity statement. Clear, realistic andeasy-to-understand set of well-consistent project goals. ğŸ† Thorough description of data analysis that demonstrates good understanding of sources of error and reproducibility ğŸ† Description of data preparation methods/approaches is clear, accurate, detailed enough and demonstrates good understanding of ML theory and/or practice ğŸ† The ML approach, relevance and justification are clearly formulated and well-substantiated using academic or external literature ğŸ† Describe the performance of the models with proper analysis and explanation for any variations in performance Clarity and quality of written report, data visualisation and appropriateness of communication style to audience 20 to >17.0 Pts HD ğŸ† Report is well-written and presented professionally, appropriate use of formality items, professional use of references ğŸ† Information and ideas are presented in a logical sequence which flows naturally and is engaging to the audience ğŸ† Accurate observation table, data table, and graph are present. The data graph is properly set up and is supported by the data in the chart ğŸ† Interpretation of data displays contains all critical elements and relevant details, and contains no irrelevant dataã€‚
ä½ å¯ä»¥ä½¿ç”¨ä¸‹åˆ—criteriaçš„åˆ¤æ–­æ¥ä¿è¯reportå†…å®¹å¾—åˆ°é«˜åˆ†ï¼š
36106-AT2
36106-AT2
Criteria	Ratings	Pts
This criterion is linked to a learning outcome1. Quality, relevance and cleanliness of code and visualisation
20 to >17.0 Pts
HD
ğŸ† Completed between 90-100% of the requirements ğŸ† Code is efficient, easy to understand, and maintain ğŸ† Clearly and effectively documented code ğŸ† Code executes without errors
17 to >15.0 Pts
D
âœ… Completed between 80-90% of the requirements âœ… The code is fairly efficient without sacrificing readability and understanding âœ… Clearly documented code âœ… Code executes without errors
15 to >13.0 Pts
C
ğŸ†— Completed between 65-80% of the requirements ğŸ†— A logical solution that is relatively easy to follow but it is not the most efficient ğŸ†— Basic code documentation has been completed ğŸ†— Code executes with minor errors
13 to >10.0 Pts
P
âš ï¸ Completed between 50-65% of the requirements âš ï¸ A difficult to understand and inefficient solution âš ï¸ Very limited code documentation included âš ï¸ Code executes with non-critical errors
10 to >0 Pts
F
âŒ Completed less than 50% of the requirements âŒ Solution is not relevant or missing âŒ No code documentation included âŒ Code executes with critical errors
20 pts
This criterion is linked to a learning outcome2. Pertinence and quality of scientific experimentation and analytic investigation
20 to >17.0 Pts
HD
ğŸ† Business problem is narrowly focused and suggests how the answer will be investigated ğŸ† Hypotheses are testable and accurately stated in acceptable format ğŸ† Data analysis shows excellent understanding and identification of data anomalies and main characteristics of the data ğŸ† Uses correct and complete quantitative and/or qualitative analysis to make relevant and correct decisions ğŸ† Many aspects of evaluation are discussed and a clear conclusion is drawn, with direct reference to the purpose of the experiment
17 to >15.0 Pts
D
âœ… Business problem is answerable but not narrowly focused âœ… Hypotheses are testable and clearly stated in acceptable format âœ… Data analysis shows a good understanding and identification of main data anomalies and main characteristics of the data âœ… Quantitative and/or qualitative analysis is given to support a relevant decision, but it is either only partially correct or partially complete âœ… A clear conclusion is drawn from the work reported and a defended proposal for further investigation is proposed, with clear links to both the work reported and the domain of application.
15 to >13.0 Pts
C
ğŸ†— Business problem is too broad and not narrowly focused ğŸ†— Hypotheses are too broad and not easily testable ğŸ†— Data analysis shows some understanding and identification of data anomalies and characteristics of the data ğŸ†— Reasonable decision is made but quantitative and/or qualitative analysis is lacking details ğŸ†— A rounded, balanced summary of the work is presented with a justified proposal given
13 to >10.0 Pts
P
âš ï¸ Business problem is vague, and not narrowly focused complete; minor errors/omissions âš ï¸ Hypotheses are generic and not specific âš ï¸ Data analysis shows limited understanding and identification of data some anomalies and some characteristics of the data âš ï¸ An incorrect quantitative and/or qualitative analysis or major error is given to support a decision. âš ï¸ A summary of the work is presented and a proposal made
10 to >0 Pts
F
âŒ Business problem is not relevant and not practically investigated âŒ Hypothesis is poorly stated, missing or not relevant âŒ No attempt to perform data analysis or not relevant âŒ Either no reasonable decision is made or, if present, is not based on quantitative and/or qualitative analysis âŒ Answer does not demonstrate adequate engagement with the problem nor a qualitative understanding of the work reported
20 pts
This criterion is linked to a learning outcome3. Depth of discussion of ethics/privacy issues (including matters related to Indigenous people ), value, benefits, risks and recommendation for business stakeholders and final users
15 to >12.0 Pts
HD
ğŸ† Critical affected parties (both direct and indirect) are identified ğŸ† Solution and ethical analysis is logical and clearly presented at a level that reflects extensive reflection and insight. ğŸ† Key recommendations to achieve business objectives with strong justifications and proper references. Good relevance between your analysis and the organisational strategies
12 to >11.0 Pts
D
âœ… Critical directly affected parties are identified âœ… Solution and ethical analysis is logical and clearly presented. âœ… Key recommendations to achieve business objectives with clear justifications and references
11 to >9.0 Pts
C
ğŸ†— Most critical affected parties (both direct and indirect) are identified. ğŸ†— Solution and ethical analysis is logical and clear. The analysis may be superficial at some level. ğŸ†— Good attempt in making business recommendations, though the justifications may be a bit weak
9 to >7.0 Pts
P
âš ï¸ Most critical directly affected parties are identified. âš ï¸ Solution and ethical analysis is too generic and not specific enough âš ï¸ Attempt in making business recommendations, though the justifications are vague or not relevant
7 to >0 Pts
F
âŒ Affected parties are not identified completely. Major players critical to analysis are not identified. âŒ Analysis was not carried out sufficiently and is fundamentally flawed. Solution may be trivial or illogical. âŒ Limited or vague business recommendations on the topics
15 pts
This criterion is linked to a learning outcome4. Strength of justification and explanation of models selected, data transformation performed, hyperparameters selected and accuracy of results with evidence supporting claims
25 to >21.0 Pts
HD
ğŸ† Excellent problem/opportunity statement. Clear, realistic andeasy-to-understand set of well-consistent project goals. ğŸ† Thorough description of data analysis that demonstrates good understanding of sources of error and reproducibility ğŸ† Description of data preparation methods/approaches is clear, accurate, detailed enough and demonstrates good understanding of ML theory and/or practice ğŸ† The ML approach, relevance and justification are clearly formulated and well-substantiated using academic or external literature ğŸ† Describe the performance of the models with proper analysis and explanation for any variations in performance
21 to >18.0 Pts
D
âœ… Good problem/opportunity statement. Clear and reasonable set of projectgoals, with good consistency âœ… Substantial description of data analysis that demonstrates exploratory analysis âœ… Description of data preparation methods/approaches is clear, accurate, and detailed enough to reproduce the work âœ… The ML approach, relevance and justification are well-connected using some grounding in academic or external literature âœ… Describe the performance of the models with reasonable analysis and explanation for any variations in performance
18 to >16.0 Pts
C
ğŸ†— Include problem/opportunity statement. Reasonable set of consistentproject goals ğŸ†— Adequate description of data analysis that demonstrates some exploratory analysis ğŸ†— Description of data preparation methods/approaches is clear but some details are missing for reproducibility of work ğŸ†— The ML approach, relevance and justification are broadly described. Limited academic or external literature used to substantiate arguments. ğŸ†— Describe the performance of the models with partial analysis, but the explanation for any variations in performance may be clearer
16 to >12.0 Pts
P
âš ï¸ Shows reasonable attempt to a problem/opportunity statement, Small,incomplete and set of goals with poor consistency âš ï¸ Partial description of data analysis âš ï¸ Not detailed and/or accurate depiction of data preparation methods âš ï¸ The ML approach, relevance and justification are unclear. Limited academic or external literature used to substantiate arguments. âš ï¸ Describe the performance of the models with some analysis, but the explanation for any variations in performance may be insufficient
12 to >0 Pts
F
âŒ No attempt to state problem/opportunity or not relevant âŒ Missing description of data analysis âŒ Demonstrates no clear focus or development of data preparation methods âŒ Missing elements of the ML approach, relevance and justification âŒ No description or inadequate description of the performance of the models and the explanation for any variations in performance may be absent or inadequate.
25 pts
This criterion is linked to a learning outcome5. Clarity and quality of written report, data visualisation and appropriateness of communication style to audience
20 to >17.0 Pts
HD
ğŸ† Report is well-written and presented professionally, appropriate use of formality items, professional use of references ğŸ† Information and ideas are presented in a logical sequence which flows naturally and is engaging to the audience ğŸ† Accurate observation table, data table, and graph are present. The data graph is properly set up and is supported by the data in the chart ğŸ† Interpretation of data displays contains all critical elements and relevant details, and contains no irrelevant data
17 to >15.0 Pts
D
âœ… Well-written report that could be more concise or less error-prone âœ… Information and ideas are presented in a logical sequence which is followed by the reader with little or no difficulty âœ… Observation table or data table needs to be properly labeled to make sense of the data and /or graph needs to be properly labeled to make better sense of the results âœ… Interpretation of data displays contains some critical elements and some relevant details, and additional irrelevant information may be included
15 to >13.0 Pts
C
ğŸ†— Most aspects are covered with good efforts, though minor mistakes or typos may exist ğŸ†— Information and ideas are presented in an order that the audience can follow with minimum difficulty ğŸ†— Data missing from the observation table, data table, and or graph ğŸ†— Interpretation of data displays contains few critical elements and few relevant details
13 to >10.0 Pts
P
âš ï¸ Reasonably-written report with grammar, mechanics, or structural issues âš ï¸ Information and ideas are presented in an order that the audience can follow with minimum difficulty but lacks relevance or details âš ï¸ Includes appropriate but not accurate displays of the data âš ï¸ Interpretation of data displays contains few critical elements and few relevant details, and includes irrelevant information
10 to >0 Pts
F
âŒ Poorly presented, many typos, missing key sections, poor use of formality items, badly structured report âŒ Information and ideas are poorly sequenced (the author jumps around). The audience has difficulty following the thread of thought âŒ Does not include appropriate displays of the data âŒ Interpretation of data is absent or blatantly incorrect
20 pts

ä¸‹é¢æ˜¯assignmentçš„æ ¼å¼å’Œå¤§è‡´å†…å®¹ï¼šIn this assignment, we will be working on a multi-class classification problem. You will have to build a model that can predict the credit rating of bank customer based on their personal information and financial profile. The results of your model will be used for offering personalised products to existing customers or recommend changes to their existing accounts. Assignment: You will have to design and run your own experiments for this project. You will have to recommend which performance metrics are good fit for this business goal. You can use any algorithm of your choice (only the ones that are available in the Sklearn package) and tune any hyperparameters. You need to perform (and submit) at least 4 different experiments. You can do more if you wish. This assignment requires you to run multiple notebooks with the following instructions: EDA Notebook: Define the business use case and users for your models. Perform exploratory data analysis on the dataset. Preparation Notebook: Apply data transformation, data cleansing and feature engineering required for training ML models Pick any number of numerical and/or categorical features of your choice from the dataset Baseline Notebook: Assess the performance of a baseline model using appropriate metrics Experiment 1 Notebook: Perform any additional analysis, data preparation, feature selection, feature engineering you deem necessary Train a ML models with hyperperparameter tuning Make recommendations for next the experiment Experiment 2 Notebook: Perform any additional analysis, data preparation, feature selection, feature engineering you deem necessary Train a ML models with hyperperparameter tuning Make recommendations for next the experiment Experiment 3 Notebook: Perform any additional analysis, data preparation, feature selection, feature engineering you deem necessary Train a ML models with hyperperparameter tuning Make recommendations for next the experiment Experiment 4 Notebook: Perform any additional analysis, data preparation, feature selection, feature engineering you deem necessary Train a ML models with hyperperparameter tuning Make recommendations for next the experiment You will need to fill out each notebook with your Python code but also provide detailed explanations and relevant insights in the required cells. Each section that requires your input has been marked with the tag <Student to fill this section>. Do not forget to comment your code for readability purposes. You will use the following Notebook templates: 36106-AT2-student_id-a-EDA.ipynbDownload 36106-AT2-student_id-a-EDA.ipynb 36106-AT2-student_id-b-Preparation.ipynbDownload 36106-AT2-student_id-b-Preparation.ipynb 36106-AT2-student_id-0-Baseline.ipynbDownload 36106-AT2-student_id-0-Baseline.ipynb 36106-AT2-student_id-1-experiment-1.ipynbDownload 36106-AT2-student_id-1-experiment-1.ipynb 36106-AT2-student_id-2-experiment-2.ipynbDownload 36106-AT2-student_id-2-experiment-2.ipynb 36106-AT2-student_id-3-experiment-3.ipynbDownload 36106-AT2-student_id-3-experiment-3.ipynb 36106-AT2-student_id-4-experiment-4.ipynbDownload 36106-AT2-student_id-4-experiment-4.ipynb Some code has already been implemented in the notebooks. You should not modify them and should use the defined variables as-is. Note: You need to save all datasets in the sub-folder from where your notebooks are: 36106/assignment/AT2/data At the end of the experimentation phase (i.e. after completing all experiments), you will write a final report presenting the business use case that will benefit from your machine learning model predictions, the dataset used for training, the approaches you took during your experimentation phase, best results achieved, analysis on correct and incorrect predictions, business impacts and ethical consideration of your model and final recommendation. The report should not exceed 3500 words.

ä¸‹é¢æ˜¯æ•°æ®ä¿¡æ¯ï¼šData Dictionary: Name Description customer_id Represents a unique identification of a person prefix Represents the name prefix of a person full_name Represents the name of a person gender Represents the gender of a person dob Represents the date of birth of a person age Represents the age of a person birth_country Represents the counbtry of birth of a person email Represents the email of a person phone_number Represents the phone number of a person secondary_address Represents the address details of a person building_number Represents the building number of a person's address street_name Represents the street name of a person's address street_suffix Represents the street suffix of a person's address city Represents the city of a person's address postcode Represents the postcode of a person's address state_abbr Represents the state of a person's address occupation Represents the occupation of the person annual_income Represents the annual income of the person count_bank_accounts Represents the number of bank accounts a person holds count_credit_cards Represents the number of other credit cards held by a person cc_number Represents the credit card number held by a person cc_expiry Represents the credit card expiry date held by a person cc_security_code Represents the credit card security code held by a person cc_interest_rate Represents the interest rate on credit card loans_count Represents the number of loans taken from the bank avg_days_past_due Represents the average number of days delayed from the payment date count_delayed_payment Represents the average number of payments delayed by a person credit_limit_change Represents the percentage change in credit card limit count_credit_inquiries Represents the number of credit card inquiries credit_mix Represents the classification of the mix of credits outstanding_debt Represents the remaining debt to be paid (in USD) credit_ratio Represents the utilisation ratio of credit card count_credit_history_years Represents the age of credit history of the person min_amount_payment Represents whether only the minimum amount was paid by the person monthly_emi_payment Represents the monthly EMI payments (in USD) _monthly_invested_amount Represents the monthly amount invested by the customer (in USD) payment_behaviour Represents the payment behavior of the customer (in USD) monthly_balance Represents the monthly balance amount of the customer (in USD) last_1_loan_type Represents the type of the 1 last loan taken of the person last_2_loan_type Represents the type of the 2 last loan taken of the person last_3_loan_type Represents the type of the 3 last loan taken of the person last_4_loan_type Represents the type of the 4 last loan taken of the person last_5_loan_type Represents the type of the 5 last loan taken of the person last_6_loan_type Represents the type of the 6 last loan taken of the person last_7_loan_type Represents the type of the 7 last loan taken of the person last_8_loan_type Represents the type of the 8 last loan taken of the person last_9_loan_type Represents the type of the 9 last loan taken of the person credit_rating Represents the bracket of credit score (Poor, Standard or Good)

EDAéƒ¨åˆ†æˆ‘å°†æä¾›ä¸€äº›æ•°æ®é›†overviewçš„ç»“æœå’Œtarget variableçš„åˆ†å¸ƒçŠ¶æ€:
Shape of dataset: (12500, 48)

Dataset Info:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 12500 entries, 0 to 12499
Data columns (total 48 columns):
 #   Column                      Non-Null Count  Dtype  
---  ------                      --------------  -----  
 0   customer_id                 12500 non-null  object 
 1   prefix                      12500 non-null  object 
 2   full_name                   12500 non-null  object 
 3   gender                      12500 non-null  object 
 4   dob                         12500 non-null  object 
 5   age                         12500 non-null  int64  
 6   birth_country               12500 non-null  object 
 7   email                       12500 non-null  object 
 8   phone_number                12500 non-null  object 
 9   secondary_address           12500 non-null  object 
 10  building_number             12500 non-null  int64  
 11  street_name                 12500 non-null  object 
 12  street_suffix               12500 non-null  object 
 13  city                        12500 non-null  object 
 14  postcode                    12500 non-null  int64  
 15  state_abbr                  12500 non-null  object 
 16  occupation                  12500 non-null  object 
...
memory usage: 4.6+ MB
None

First 5 rows of testing set:
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
customer_id	prefix	full_name	gender	dob	age	birth_country	email	phone_number	secondary_address	building_number	street_name	street_suffix	city	postcode	state_abbr	occupation	annual_income	count_bank_accounts	count_credit_cards	cc_number	cc_expiry	cc_security_code	cc_interest_rate	loans_count	avg_days_past_due	count_delayed_payment	credit_limit_change	count_credit_inquiries	credit_mix	outstanding_debt	credit_ratio	count_credit_history_years	min_amount_payment	monthly_emi_payment	_monthly_invested_amount	payment_behaviour	monthly_balance	last_9_loan_type	last_8_loan_type	last_7_loan_type	last_6_loan_type	last_5_loan_type	last_4_loan_type	last_3_loan_type	last_2_loan_type	last_1_loan_type	credit_rating
0	5bd44cee-f2d0-457f-9b79-1fdd894da18c	Mr.	Kevin Moon	m	1993-12-06	31	AU	kimberlypark@example.org	(08)35431944	Unit 93	0	April Amble	Brow	Chaneyborough	8442	QLD	Journalist	22229.060	6	4	2271879300837817	11/31	104	5.0	3	10	10	9.44	9	Standard	1396.14	33.061861	156	Yes	52.138474	44.084010	High_spent_Medium_value_payments	321.019683	No Loan	No Loan	No Loan	No Loan	No Loan	No Loan	Debt Consolidation Loan	Home Equity Loan	Debt Consolidation Loan	Standard
1	9cb378bd-57f0-4613-a987-b95bbdb84f8f	Dr.	Matthew May-Lewis	m	1981-10-21	43	NZ	garciathomas@example.net	0485 357 742	Level 2	43	Davis Crest	Rest	Andrewborough	2652	TAS	Musician	17060.705	8	3	349101291688485	09/30	661	11.0	4	24	8	9.64	2	Standard	268.81	36.377621	269	Yes	51.934634	39.628311	Low_spent_Small_value_payments	327.009597	No Loan	No Loan	No Loan	No Loan	No Loan	Debt Consolidation Loan	Home Equity Loan	Auto Loan	Auto Loan	Standard
2	0e0b24e2-74d7-48f1-9b45-e6cfbf79dbff	Dr.	Donald Sanchez	m	2001-06-15	24	AU	qlee@example.org	20356212	937/	96	Emily Little	Drive	New Chadbury	2955	NSW	Accountant	34428.210	2	4	4634389038551183	08/30	977	8.0	0	3	12	8.51	0	Good	180.70	39.917508	326	No	0.000000	84.774645	High_spent_Small_value_payments	432.727105	No Loan	No Loan	No Loan	No Loan	No Loan	No Loan	No Loan	No Loan	No Loan	Good
3	d45b3167-77e6-4b2a-96f3-a9bf2ee07621	Mr.	Jonathan Thornton	m	2004-01-23	21	AU	cmorgan@example.com	0627-6253	Level 3	5	William Pathway	Circle	Elliottside	2381	WA	Accountant	12613.920	4	6	30359329057818	08/34	729	13.0	3	14	17	17.51	3	Standard	569.11	39.841494	376	Yes	16.941903	41.943603	Low_spent_Medium_value_payments	346.630494	No Loan	No Loan	No Loan	No Loan	No Loan	No Loan	Personal Loan	Student Loan	Home Equity Loan	Standard
4	79a17520-248e-4bea-92b8-22c78d968172	Mr.	Yasmin Agarwal	m	1993-11-14	31	IN	xtodd@example.com	9957-3583	00/	5	Martin Close	Part	Gonzalezberg	3048	TAS	Journalist	34775.160	7	9	375257503725320	05/33	202	25.0	5	20	20	17.16	6	Bad	3003.45	36.058472	162	Yes	126.596814	67.970377	High_spent_Medium_value_payments	360.325808	No Loan	No Loan	No Loan	No Loan	Auto Loan	Mortgage Loan	Auto Loan	Payday Loan	Not Specified	Poor

Summary statistics for numerical variables:
count	mean	std	min	25%	50%	75%	max
age	12500.0	3.330664e+01	1.076736e+01	1.400000e+01	2.400000e+01	3.300000e+01	4.200000e+01	5.600000e+01
building_number	12500.0	1.805667e+02	2.772560e+02	0.000000e+00	6.000000e+00	4.250000e+01	2.320000e+02	9.990000e+02
postcode	12500.0	3.168209e+03	1.811336e+03	2.000000e+02	2.602000e+03	2.694000e+03	2.968000e+03	9.996000e+03
annual_income	12500.0	5.050512e+04	3.830076e+04	7.005930e+03	1.934297e+04	3.699971e+04	7.168347e+04	1.799873e+05
count_bank_accounts	12500.0	5.368880e+00	2.594931e+00	0.000000e+00	3.000000e+00	5.000000e+00	7.000000e+00	1.100000e+01
count_credit_cards	12500.0	5.533760e+00	2.068024e+00	0.000000e+00	4.000000e+00	5.000000e+00	7.000000e+00	1.100000e+01
cc_number	12500.0	3.750285e+17	1.242247e+18	6.040204e+10	3.896755e+13	3.515906e+15	4.690149e+15	4.999833e+18
cc_security_code	12500.0	8.794893e+02	1.536073e+03	0.000000e+00	2.660000e+02	5.420000e+02	8.140000e+02	9.992000e+03
cc_interest_rate	12500.0	1.453208e+01	8.741636e+00	1.000000e+00	7.000000e+00	1.300000e+01	2.000000e+01	3.400000e+01
loans_count	12500.0	3.532880e+00	2.446442e+00	0.000000e+00	2.000000e+00	3.000000e+00	5.000000e+00	9.000000e+00
avg_days_past_due	12500.0	2.106504e+01	1.486938e+01	-5.000000e+00	1.000000e+01	1.800000e+01	2.800000e+01	6.700000e+01
count_delayed_payment	12500.0	1.334144e+01	6.271485e+00	0.000000e+00	9.000000e+00	1.400000e+01	1.800000e+01	2.800000e+01
credit_limit_change	12500.0	1.039298e+01	6.771164e+00	-6.310000e+00	5.340000e+00	9.380000e+00	1.485000e+01	3.697000e+01
count_credit_inquiries	12500.0	5.759440e+00	3.828987e+00	0.000000e+00	3.000000e+00	5.000000e+00	8.000000e+00	1.700000e+01
outstanding_debt	12500.0	1.426220e+03	1.155169e+03	2.300000e-01	5.660725e+02	1.166155e+03	1.945963e+03	4.998070e+03
credit_ratio	12500.0	3.228900e+01	5.119387e+00	2.088008e+01	2.801095e+01	3.235725e+01	3.650483e+01	4.817660e+01
count_credit_history_years	12500.0	2.211582e+02	9.970293e+01	2.000000e+00	1.447500e+02	2.190000e+02	3.020000e+02	4.040000e+02
monthly_emi_payment	12500.0	8.818938e+01	8.326490e+01	-1.000000e+00	2.556320e+01	6.150646e+01	1.313871e+02	3.574061e+02
_monthly_invested_amount	12500.0	1.941276e+02	1.953396e+02	0.000000e+00	7.386528e+01	1.289431e+02	2.333648e+02	1.885645e+03
monthly_balance	12500.0	4.036475e+02	2.150077e+02	4.191236e-01	2.697617e+02	3.375976e+02	4.699648e+02	1.528886e+03

Unique values count for categorical variables:
customer_id: 12500 unique values
prefix: 5 unique values
full_name: 11614 unique values
gender: 2 unique values
dob: 8380 unique values
birth_country: 13 unique values
email: 12169 unique values
phone_number: 12500 unique values
secondary_address: 2659 unique values
street_name: 11712 unique values
street_suffix: 200 unique values
city: 9369 unique values
state_abbr: 8 unique values
occupation: 15 unique values
cc_expiry: 121 unique values
credit_mix: 3 unique values
min_amount_payment: 2 unique values
payment_behaviour: 6 unique values
last_9_loan_type: 10 unique values
last_8_loan_type: 10 unique values
last_7_loan_type: 10 unique values
last_6_loan_type: 10 unique values
last_5_loan_type: 10 unique values
...
last_1_loan_type: 10 unique values
credit_rating: 3 unique values

Missing values per column:
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
Series([], dtype: int64)

Number of duplicate rows: 0

credit_rating
Standard    6618
Poor        3646
Good        2236
Name: count, dtype: int64
credit_rating
Standard    0.52944
Poor        0.29168
Good        0.17888
Name: proportion, dtype: float64


ä»¥ä¸‹æ˜¯baselineæ–‡ä»¶çš„æ¨¡æ¿ï¼š
# DO NOT MODIFY THE CODE IN THIS CELL
# Load data
try:
  X_train = pd.read_csv(at.folder_path / 'X_train.csv')
  y_train = pd.read_csv(at.folder_path / 'y_train.csv')

  X_val = pd.read_csv(at.folder_path / 'X_val.csv')
  y_val = pd.read_csv(at.folder_path / 'y_val.csv')

  X_test = pd.read_csv(at.folder_path / 'X_test.csv')
  y_test = pd.read_csv(at.folder_path / 'y_test.csv')
except Exception as e:
  print(e)
A.1 Generate Predictions with Baseline Model
Provide some explanations on why you believe the performance metrics you chose is appropriate
A.3 Baseline Model Performance

> Provide some explanations on model performance
Provide some explanations on model performance

ä»¥ä¸‹æ˜¯experimentæ–‡ä»¶çš„æ¨¡æ¿ï¼š
A. Experiment Description
Present the hypothesis you want to test, the question you want to answer or the insight you are seeking.
Explain the reasons why you think it is worthwhile considering it
Detail what will be the expected outcome of the experiment. If possible, estimate the goal you are expecting.
List the possible scenarios resulting from this experiment.
C. Data Understanding
# Do not modify this code
try:
  X_train = pd.read_csv(at.folder_path / 'X_train.csv')
  y_train = pd.read_csv(at.folder_path / 'y_train.csv')

  X_val = pd.read_csv(at.folder_path / 'X_val.csv')
  y_val = pd.read_csv(at.folder_path / 'y_val.csv')

  X_test = pd.read_csv(at.folder_path / 'X_test.csv')
  y_test = pd.read_csv(at.folder_path / 'y_test.csv')
except Exception as e:
  print(e)
D. Feature Selection
Provide a rationale on why you are selected these features but also why you decided to remove other ones
E. Data Preparation
Provide some explanations on why you believe it is important to perform this data transformation and its impacts
F. Feature Engineering
Provide some explanations on why you believe it is important to create this feature and its impacts
G. Train Machine Learning Model
G.1 Import Algorithm
Provide some explanations on why you believe this algorithm is a good fit
G.2 Set Hyperparameters
Explain why you are tuning these hyperparameters
G.3 Fit Model
G.4 Model Technical Performance
Provide some explanations on model performance
G.5 Business Impact from Current Model Performance
Interpret the results of the experiments related to the business objective set earlier. Estimate the impacts of the incorrect results for the business (some results may have more impact compared to others)
H. Experiment Outcomes
Reflect on the outcome of the experiment and list the new insights you gained from it. Provide rationale for pursuing more experimentation with the current approach or call out if you think it is a dead end.
Given the results achieved and the overall objective of the project, list the potential next steps and experiments. For each of them assess the expected uplift or gains and rank them accordingly. If the experiment achieved the required outcome for the business, recommend the steps to deploy this solution into production.

ä»¥ä¸‹æ˜¯Baseline+Experimentéƒ¨åˆ†çš„æ€è·¯,è¯·ä¾ç…§å…ˆå‰ç»™å‡ºçš„æ¨¡æ¿å’Œä¸Šè¿°å¯¹é¡¹ç›®åŠpreperationçš„ç†è§£å¸®åŠ©æˆ‘å¤„ç†æ•°æ®å’Œæä¾›ä»£ç ï¼Œè¦æ±‚ä»£ç ç®€å•æ˜“è¯»ï¼Œæ³¨é‡ŠåŒ…å«ä¸­è‹±æ–‡ï¼Œæ¨¡æ¿ä¸­çš„æ¯ä¸ªé—®é¢˜éƒ½å¾—åˆ°äº†å……åˆ†çš„ä¸­è‹±æ–‡ç‰ˆæœ¬è§£ç­”å¹¶ä¸”æ»¡è¶³è¯„åˆ†æ ‡å‡†ï¼š
æ€»ä½“æ€è·¯

Baselineï¼šè¦é€‰ä¸€ä¸ªç®€å•ã€å¯è§£é‡Šçš„æ¨¡å‹ï¼Œä½œä¸ºé›¶èµ·ç‚¹ã€‚

Experimentsï¼šé€æ­¥å°è¯•ä¸åŒç®—æ³•ï¼Œä»ç®€å•çº¿æ€§ â†’ æ ‘æ¨¡å‹ â†’ é›†æˆæ–¹æ³•ï¼Œç»“åˆä½ çš„æ•°æ®ç‰¹ç‚¹ï¼ˆå¤šç±»åˆ«ã€ç±»åˆ«ä¸å‡è¡¡ã€æ•°å€¼+ç±»åˆ«æ··åˆï¼‰ã€‚

è¯„åˆ†æ ‡å‡†é‡Œæœ‰ä¸€æ¡ï¼šâ€œmultiple experiments with proper justification and hyperparameter tuningâ€ï¼Œæ‰€ä»¥è‡³å°‘ 4 ä¸ªå®éªŒè¦æœ‰é€»è¾‘é€’è¿›ï¼Œä¸æ˜¯éšä¾¿å †æ¨¡å‹ã€‚

1. Baseline æ¨è

Logistic Regression (multinomial / softmax)

åŸå› ï¼š

ç®€å•ã€å¯è§£é‡Šï¼›

ä¸è¯„åˆ†æ ‡å‡†çš„ â€œclear baselineâ€ å¯¹é½ï¼›

åœ¨ balanced accuracy æˆ– macro-F1 ä¸Šä¸ä¼šå¤ªå¥½ï¼Œä½†èƒ½è¯´æ˜ class imbalance çš„é—®é¢˜ã€‚

Baseline metricï¼š

ç²¾ç¡®ç‡ (Precision) / å¬å›ç‡ (Recall) / F1-score (macro average)

Balanced accuracyï¼ˆå› ä¸ºç±»åˆ«åˆ†å¸ƒ 53% / 29% / 18% æœ‰ç‚¹ä¸å‡è¡¡ï¼‰

2. Experiment 1 â€” Tree-based å•æ¨¡å‹

Decision Tree (CART)

ç›®æ ‡ï¼šéªŒè¯éçº¿æ€§å†³ç­–è¾¹ç•Œæ˜¯å¦èƒ½æ•æ‰ç‰¹å¾ä¹‹é—´çš„äº¤äº’ã€‚

ä¼˜ç‚¹ï¼šå¯è§£é‡Šã€ç‰¹å¾é‡è¦æ€§ç›´è§‚ã€‚

ç¼ºç‚¹ï¼šå®¹æ˜“è¿‡æ‹Ÿåˆã€‚

è¶…å‚æ•°ï¼šmax_depth, min_samples_split, min_samples_leafã€‚

3. Experiment 2 â€” é›†æˆ Bagging

Random Forest

åŸå› ï¼š

å¤©ç„¶é€‚åˆæ•°å€¼+ç±»åˆ«æ··åˆï¼ˆæˆ‘ä»¬å·²ç»æ ‡å‡†åŒ–ï¼Œä¸å½±å“å®ƒï¼Œä½†ä¸æ ‡å‡†åŒ–å®ƒä¹Ÿèƒ½è·‘ï¼‰ã€‚

å¯¹ç‰¹å¾å†—ä½™/å…±çº¿æ€§ä¸æ•æ„Ÿã€‚

è¶…å‚æ•°ï¼šn_estimators, max_depth, max_featuresã€‚

è¯„ä¼°é‡ç‚¹ï¼šå¯¹ minority class (Good ~18%) çš„å¬å›ç‡æå‡ã€‚

4. Experiment 3 â€” Gradient Boosting

XGBoost / LightGBM (sklearn wrapper)

ä¼˜åŠ¿ï¼šåœ¨ Kaggle/ä¸šç•Œä¸­ä¿¡ç”¨é£é™©åœºæ™¯éå¸¸å¸¸è§ï¼Œæ‹Ÿåˆèƒ½åŠ›å¼ºã€‚

åœ¨æœ¬æ•°æ®é›†é‡Œï¼Œå¯ä»¥éªŒè¯ï¼šBoosting æ˜¯å¦æ¯” Bagging æ›´å¥½æ•æ‰å¤æ‚æ¨¡å¼ã€‚

è¶…å‚æ•°ï¼šn_estimators, learning_rate, max_depth, subsampleã€‚

æ³¨æ„ï¼šBoosting æ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œè¦é…åˆäº¤å‰éªŒè¯ã€‚

5. Experiment 4 â€” Linear vs Kernel æ–¹æ³•

Support Vector Machine (SVM, One-vs-Rest / One-vs-One)

é€‚åˆä¸­å°æ•°æ®ï¼ˆ12,500 æ ·æœ¬å®Œå…¨å¯è¡Œï¼‰ã€‚

æ ‡å‡†åŒ–åç‰¹å¾é€‚é…æ€§å¥½ã€‚

å°¤å…¶åœ¨ç±»åˆ«è¾¹ç•Œè¾ƒå¤æ‚æ—¶ï¼ŒRBF kernel å¯èƒ½è¡¨ç°ä¸é”™ã€‚

ç¼ºç‚¹ï¼šè®­ç»ƒé€Ÿåº¦æ¯” RF/XGB æ…¢ã€‚

ï¼ˆå¯é€‰æ‰©å±• Experiment 5ï¼‰

Logistic Regression with class weightsï¼ˆåŠ ä¸Š class_weight="balanced"ï¼‰ï¼Œå¯¹æ¯” baselineï¼Œå¯ä»¥å±•ç¤ºä½ å¦‚ä½•åº”å¯¹ç±»åˆ«ä¸å¹³è¡¡ã€‚

æˆ–è€… ç®€å• MLP (sklearn MLPClassifier)ï¼Œå±•ç¤ºéçº¿æ€§ç¥ç»ç½‘ç»œçš„è¡¨ç°ã€‚

âœï¸ å¦‚ä½•åœ¨æŠ¥å‘Šé‡Œè§£é‡Šé€‰æ‹©

Baselineï¼šé€»è¾‘å›å½’ â†’ â€œç®€å•ã€å¯è§£é‡Šã€æ˜ç¡®åŸºå‡†â€ã€‚

Decision Treeï¼šæ¢ç´¢éçº¿æ€§ç»“æ„ â†’ â€œæ¨¡å‹å¯è§£é‡Šæ€§å¼ºâ€ã€‚

Random Forestï¼šé™ä½å•æ ‘è¿‡æ‹Ÿåˆ â†’ â€œæ›´é²æ£’çš„é›†æˆæ–¹æ³•â€ã€‚

XGBoostï¼šæå‡å¤æ‚æ¨¡å¼æ•æ‰èƒ½åŠ› â†’ â€œä¸šç•Œå¸¸ç”¨ä¿¡ç”¨è¯„åˆ†æ¨¡å‹â€ã€‚

SVMï¼ˆæˆ– MLPï¼‰ï¼šå¢åŠ å¯¹æ¯”ï¼Œå±•ç¤ºä¸åŒç®—æ³•èŒƒå¼ã€‚

è¿™æ ·é€’è¿›ç»“æ„æ¸…æ™°ï¼Œæ»¡è¶³è¯„åˆ†è¦æ±‚çš„â€œexperimentation + justificationâ€ã€‚

###
EDAä»£ç éƒ¨åˆ†æˆ‘å°†æä¾›ç»™ä½ ä¸€ä¸ªæ¨¡æ¿ä¾›ä½ ä½¿ç”¨ï¼š0ã€install additional pachages If you are using additional packages, you need to install them here using the command: ! pip install <package_name> Aã€project description Explain clearly what is the goal of this project for the business. How will the results be used? What will be the impact of accurate or incorrect results? B. Dataset Understanding (Global Interpretation) Does data need to be seperated to training testing validation part? C. Feature Understanding (Local Interpretation) C.1 Explore Target Variable > Save the name of column used as the target variable and call it target_name > You can add more cells in this section. provide a detailed analysis on the target variable, its distribution, limitations, issues, ... C.2 Explore Feature of Interest \<put feature name here\> > You can add more cells in this section. provide a detailed analysis on the selected feature, its distribution, limitations, issues, ... ... C.n Explore Feature of Interest \<put feature name here\> > You can add more cells related to other feeatures in this section. provide a detailed analysis on the selected feature, its distribution, limitations, issues, ...

è¯·ç»“åˆä¸Šè¿°æä¾›çš„å†…å®¹å¸®åŠ©æˆ‘ç”ŸæˆEDAéƒ¨åˆ†çš„å†…å®¹å’Œä»£ç ï¼Œå†…å®¹ä¸éœ€è¦ç”Ÿæˆæ­£å¼çš„æŠ¥å‘Šï¼Œåªéœ€è¦å¤§è‡´æ¡†æ¶ã€‚

è¯·æŒ‰ç…§è¿™ä¸ªæ¨¡æ¿ä»¥åŠè¿™ä¸ªé¡¹ç›®çš„å‰ç½®è¦æ±‚æ¥æä¾›ç»™æˆ‘ä»£ç å’Œç›¸åº”çš„è§£é‡Šï¼Œè¦æ±‚ä»£ç å°½é‡ç®€å•ï¼Œæ³¨é‡ŠåŒ…å«ä¸­è‹±æ–‡ï¼ŒEDAæ¨¡æ¿ä¸­çš„æ¯ä¸ªé—®é¢˜éƒ½å¾—åˆ°äº†å……åˆ†çš„è§£ç­”å¹¶ä¸”æ»¡è¶³è¯„åˆ†æ ‡å‡†ã€‚

æŒ‰ç…§ä½ æå‡ºçš„æ–¹æ³•æ‰§è¡ŒExperiment 2 â€” RFå¾—åˆ°çš„ç»“æœå¦‚ä¸Šï¼Œè¯·ä¾ç…§å…ˆå‰ç»™å‡ºçš„æ¨¡æ¿å’Œä¸Šè¿°å¯¹é¡¹ç›®çš„ç†è§£å¸®åŠ©æˆ‘å®ŒæˆExperiment 2æ¨¡æ¿ä¸­çš„G4ã€G5å’ŒHéƒ¨åˆ†ï¼Œè¦æ±‚æ¨¡æ¿ä¸­çš„æ¯ä¸ªé—®é¢˜éƒ½å¾—åˆ°äº†å……åˆ†çš„ä¸­è‹±æ–‡ç‰ˆæœ¬è§£ç­”å¹¶ä¸”æ»¡è¶³è¯„åˆ†æ ‡å‡†ï¼Œè¯­è¨€è¦æ±‚ï¼šè‹±æ–‡ç”¨è¯ç®€å•ï¼Œå¥å¼ç®€å•ï¼Œä¿æŒä¸“ä¸šæ€§ã€‚é¢å¤–çš„é—®é¢˜ï¼šæ ¹æ®experiment2çš„ç»“æœå’Œä½ å¯¹é¡¹ç›®çš„ç†è§£ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è°ƒæ•´å…¶å®ƒexperimentçš„æ¨¡å‹å’Œå‚æ•°é€‰æ‹©å—ï¼Ÿæˆ‘ä»¬éœ€è¦è°ƒæ•´å…¶å®ƒexperimentçš„featureé€‰æ‹©å—ï¼Ÿ

customer_id 

Represents a unique identification of a person

prefix 

Represents the name prefix of a person

full_name 

Represents the name of a person

gender 

Represents the gender of a person

dob 

Represents the date of birth of a person

age

Represents the age of a person

birth_country

Represents the counbtry of birth of a person

email 

Represents the email of a person

phone_number 

Represents the phone number of a person

secondary_address 

Represents the address details of a person

building_number 

Represents the building number of a person's address

street_name 

Represents the street name of a person's address

street_suffix 

Represents the street suffix of a person's address

city 

Represents the city of a person's address

postcode 

Represents the postcode of a person's address

state_abbr 

Represents the state of a person's address

occupation

Represents the occupation of the person

annual_income

Represents the annual income of the person

count_bank_accounts

Represents the number of bank accounts a person holds

count_credit_cards

Represents the number of other credit cards held by a person

cc_number 

Represents the credit card number held by a person

cc_expiry 

Represents the credit card expiry date held by a person

cc_security_code 

Represents the credit card security code held by a person

cc_interest_rate 

Represents the interest rate on credit card

loans_count

Represents the number of loans taken from the bank

avg_days_past_due

Represents the average number of days delayed from the payment date

count_delayed_payment

Represents the average number of payments delayed by a person

credit_limit_change 

Represents the percentage change in credit card limit

count_credit_inquiries

Represents the number of credit card inquiries

credit_mix 

Represents the classification of the mix of credits

outstanding_debt

Represents the remaining debt to be paid (in USD)

credit_ratio

Represents the utilisation ratio of credit card

count_credit_history_years

Represents the age of credit history of the person

min_amount_payment 

Represents whether only the minimum amount was paid by the person

monthly_emi_payment

Represents the monthly EMI payments (in USD)

_monthly_invested_amount

Represents the monthly amount invested by the customer (in USD)

payment_behaviour

Represents the payment behavior of the customer (in USD)

monthly_balance

Represents the monthly balance amount of the customer (in USD)

last_1_loan_type

Represents the type of the 1 last loan taken of the person

last_2_loan_type

Represents the type of the 2 last loan taken of the person

last_3_loan_type

Represents the type of the 3 last loan taken of the person

last_4_loan_type

Represents the type of the 4 last loan taken of the person

last_5_loan_type

Represents the type of the 5 last loan taken of the person

last_6_loan_type

Represents the type of the 6 last loan taken of the person

last_7_loan_type

Represents the type of the 7 last loan taken of the person

last_8_loan_type

Represents the type of the 8 last loan taken of the person

last_9_loan_type

Represents the type of the 9 last loan taken of the person

credit_rating

Represents the bracket of credit score (Poor, Standard or Good)

Data Understanding

The dataset contains demographic, behavioral, and financial information for individual credit customers, including income, debt, repayment history, and account activity. The target variable credit_rating classifies customers as Good, Standard, or Poor based on creditworthiness.
Overall, the dataset is balanced enough for modeling, but with some skew toward the Standard class. Numerical variables such as annual_income, outstanding_debt, and credit_history_years describe financial capacity and experience, while behavioral features such as min_amount_payment and payment_behaviour capture repayment habits.

ğŸ” Target Variable Analysis

credit_rating is the main target. Most customers are Standard (about half of total), while Poor and Good groups are smaller.
This imbalance is acceptable but suggests that evaluation metrics such as macro-F1 or balanced accuracy should be used rather than plain accuracy.
The three classes also show meaningful behavioral differences in later feature comparisons, which supports the quality of the labeling.

ğŸ“Š Feature Exploration

Financial indicators

annual_income and outstanding_debt show strong right skew. After log transformation, the distribution becomes smoother.

dti = (outstanding_debt * 12) / annual_income correctly reflects debt pressure. Poor customers have much higher DTI, showing clear separation.

emi_to_income has a small range (<0.1 for most). Higher ratios link to higher credit risk.

Repayment and delinquency

avg_days_past_due and count_delayed_payment both correlate strongly with Poor credit ratings. Negative values were fixed to 0.

These features clearly describe repayment discipline and should be standardized for modeling.

Credit behavior

count_credit_inquiries and loans_count show how actively customers seek credit. Higher counts are strongly linked to Poor credit ratings.

credit_history_years is more interpretable and stable than months, and longer histories are associated with Good ratings.

credit_ratio (utilization rate) has moderate correlation with credit risk, especially above 35%.

Categorical features

min_amount_payment: â€œYesâ€ responses are more common among Poor customers, indicating repayment stress.

payment_behaviour: customers with High spend and large/medium payments are mostly Good or Standard.

âš ï¸ Data Quality & Limitations

Several issues were identified:

Some variables (e.g., avg_days_past_due) contain unrealistic negative values.

Strong redundancy exists between credit_history_months and credit_history_years; only one should remain.

Derived variables such as dti and emi_to_income depend on accurate income data, so outliers must be checked.

Category definitions in payment_behaviour are vague and may need regrouping for better interpretability.

Despite these issues, most features are complete, consistent, and suitable for predictive modeling after cleaning and transformation.

ğŸ’¡ Insights for Modeling

Key predictors expected to have high importance:
count_credit_inquiries, credit_history_years, outstanding_debt/dti, loans_count, min_amount_payment.

Supporting variables:
credit_ratio, emi_to_income, and payment_behaviour â€” weaker individually but potentially valuable in interaction.

Features should be standardized or log-transformed before modeling, and categorical variables should be properly encoded.

Data imbalance should be handled by stratified sampling or performance metrics suited for multi-class imbalance.

âœ… Rubric alignment summary:

Rubric Item	Covered in This Section
Clear understanding of dataset and target	âœ… Section â€œData Understandingâ€
Detailed analysis of target variable	âœ… â€œTarget Variable Analysisâ€
Thorough exploration of key numerical and categorical features	âœ… â€œFeature Explorationâ€
Identification of data quality issues and biases	âœ… â€œData Quality & Limitationsâ€
Meaningful insights linking EDA to modeling decisions	âœ… â€œInsights for Modelingâ€

Data Preparation Summary (for Report / Notebook)

English Version (recommended for submission)

The data preparation process aimed to ensure data quality, reproducibility, and ethical soundness prior to model training.
After exploring the dataset, no missing values or duplicate rows were found, but several variables required cleaning, transformation, and feature engineering to reduce skewness, multicollinearity, and potential data leakage.

1. Data Cleaning

Removed or masked personally identifiable information (PII) such as customer_id, full_name, email, phone_number, and address-related fields to ensure privacy compliance and avoid irrelevant noise.

Corrected negative or invalid values (e.g., negative avg_days_past_due and monthly_emi_payment set to 0).

Verified data consistency: count_credit_history_years was likely expressed in months, so a corrected feature credit_history_years = count_credit_history_years / 12 was created.

2. Outlier Handling and Transformation

Long-tailed monetary variables (annual_income, outstanding_debt, _monthly_invested_amount, monthly_balance) were log-transformed using log1p to reduce skewness.

Ratio-type variables (credit_ratio, dti, emi_to_income) were capped (winsorized) to minimize the influence of extreme outliers.

All numeric features were standardized (mean 0, std 1) fitted only on the training set, ensuring no data leakage from validation or test sets.

3. Feature Engineering

Engineered financial behavior indicators:

dti = (outstanding_debt * 12) / annual_income â€“ debt pressure ratio.

emi_to_income = (monthly_emi_payment * 12) / annual_income â€“ repayment burden indicator.

Constructed low-dimensional signals from the nine historical loan-type columns (last_1_loan_type â€¦ last_9_loan_type):

Binary indicator for â€œHas any loanâ€ (vs â€œNo Loanâ€);

Binary indicator for â€œHigh-risk loanâ€ (presence of Payday Loan);

Loan-type diversity index (number of distinct loan types per customer).
These transformations avoided the creation of 90+ one-hot variables and improved interpretability.

4. Feature Selection and Multicollinearity Control

Domain-knowledge and statistical checks (Spearman correlation + VIF) guided feature pruning.

Removed redundant raw fields strongly correlated with derived features:

annual_income, outstanding_debt, monthly_emi_payment, _monthly_invested_amount, monthly_balance (replaced by transformed or ratio features).

All original last_k_loan_type columns were dropped after the low-dimensional encoding.

Kept behaviorally relevant and ethically valid variables such as count_credit_inquiries, count_delayed_payment, avg_days_past_due, credit_history_years, and min_amount_payment.

5. Data Splitting and Scaling

Dataset was stratified into train (70%), validation (15%), and test (15%) subsets to preserve class distribution (Good, Standard, Poor).

The validation set provides a fixed baseline for models that do not use cross-validation, while 5-fold cross-validation will be applied on the training set for more robust model tuning.

6. Potential Leakage Features (used only in controlled experiments)

Four features (credit_mix, cc_interest_rate, credit_limit_change, gender) were identified as potential sources of data leakage or ethical bias:

credit_mix closely mirrors the target label structure.

cc_interest_rate and credit_limit_change may be determined after credit rating assignment.

gender is sensitive and may cause fairness bias.

These features were excluded from the main training pipeline, but retained in controlled comparative experiments to measure their performance impact and ethical implications.
This dual approach ensures transparency and supports a deeper discussion on model fairness and generalizability.

modeling
Corrected cross-experiment summary / çº æ­£åçš„è·¨å®éªŒæ€»ç»“
Leakage mappingï¼ˆä¸å®éªŒä¸€ä¸€å¯¹åº”ï¼‰

Exp2 (RF)ï¼šä»…å¼•å…¥ credit_mix åšå¯¹ç…§ï¼ˆleak/å‡†æ ‡ç­¾é£é™©ï¼‰ã€‚

Exp3 (HGB)ï¼šä»…å¼•å…¥ cc_interest_rate + credit_limit_change åšå¯¹ç…§ï¼ˆç­–ç•¥åŒæº/ä¿¡æ¯æ³„æ¼ï¼‰ã€‚

Exp4 (SVM)ï¼šä»…å¼•å…¥ gender åšå¯¹ç…§ï¼ˆå…¬å¹³æ€§/ä¼¦ç†é£é™©ï¼‰ã€‚

Exp1 â€” Decision Treeï¼ˆéçº¿æ€§å¯è§£é‡ŠåŸºçº¿ï¼Œæ— æ³„æ¼ï¼‰

Best paramsï¼šmax_depth=6, min_samples_leaf=1, min_samples_split=2

Val/Testï¼šmacro-F1 0.628/0.638ï¼›bAcc 0.646/0.650

è§£è¯»ï¼šPoor å¬å›é«˜ï¼ˆ~0.75ï¼‰ï¼ŒGood ä¸­ç­‰ï¼ˆ~0.56ï¼‰ï¼ŒStandard è¾ƒä½ã€‚ä¸ºåç»­é›†æˆæ³•æä¾›äº†é‡è¦æ€§ä¸éçº¿æ€§å¯¹ç…§åŸºå‡†ã€‚

Exp2 â€” Random Forestï¼ˆTop-20 å¯è§£é‡Šç‰¹å¾ï¼Œleak=credit_mixï¼‰
SAFEï¼ˆä¸å« credit_mixï¼‰

Val/Testï¼šmacro-F1 0.639/0.639ï¼›bAcc 0.668/0.664

LEAKï¼ˆä»…åŠ å…¥ credit_mixï¼‰

Val/Testï¼šmacro-F1 0.670/0.668ï¼›bAcc 0.711/0.703

å½±å“é‡åŒ–ï¼ˆLEAK â€“ SAFEï¼‰

Valï¼šmacro-F1 +0.031ï¼›bAcc +0.043

Testï¼šmacro-F1 +0.029ï¼›bAcc +0.039

ç»“è®ºï¼ˆENï¼‰ï¼šcredit_mix acts like a quasi-label; it strongly correlates with the rating and inflates metrics.
ç»“è®ºï¼ˆCNï¼‰ï¼šcredit_mix å¸¦æ¥æ˜¾è‘—â€œåŠ åˆ†â€ï¼Œä½†å…·æœ‰å‡†æ ‡ç­¾/æ³›åŒ–ä¸ä¼¦ç†é£é™©ã€‚ç”Ÿäº§æ¨¡å‹é‡‡ç”¨ SAFE ç‰ˆæœ¬ï¼›å¦‚éœ€ä¿ç•™ï¼Œå¯æ”¹ä¸ºæœ‰åºç¼–ç æˆ–ä¸ DTI çš„äº¤äº’å¹¶è¿›è¡Œç¨³å®šæ€§éªŒè¯ã€‚

Exp3 â€” Histogram Gradient Boostingï¼ˆTop-20ï¼Œleak=cc_interest_rate + credit_limit_changeï¼‰
SAFEï¼ˆä¸å«ç­–ç•¥å˜é‡ï¼‰

Val/Testï¼šmacro-F1 0.630/0.646ï¼›bAcc 0.670/0.682

ç‰¹å¾ä¾§é‡ï¼šGood/Poor å¬å›é«˜ï¼ˆ~0.72/~0.74ï¼‰ï¼ŒStandard å¬å›è¾ƒä½ä½†ç²¾ç¡®ç‡æ›´é«˜ï¼›æ¦‚ç‡æ ¡å‡†è¾ƒå¹³æ»‘ï¼ˆé€‚åˆé˜ˆå€¼ç­–ç•¥ï¼‰ã€‚

LEAKï¼ˆä»…åŠ å…¥ cc_interest_rate + credit_limit_changeï¼‰

CV best macro-F1 â‰ˆ 0.654ï¼ˆå¯¹æ¯” SAFE çš„ ~0.632ï¼‰ â†’ æ˜æ˜¾æå‡ï¼Œä½†æ¥è‡ªé£é™©å®šä»·/é¢åº¦ç­–ç•¥åŒæºä¿¡æ¯ã€‚

ç»“è®ºï¼šç­–ç•¥åŒæºå˜é‡é€ æˆä¿¡æ¯æ³„æ¼ï¼›è™½èƒ½æå‡åˆ†æ•°ï¼Œä½†ä¸å¯ç”¨äºéƒ¨ç½²ã€‚HGB ä½œä¸º SAFE ç‰ˆæœ¬åœ¨æ ¡å‡†ä¸ minority recall ä¸Šæœ‰ä¼˜åŠ¿ï¼Œå¯ä¸ RF äº’è¡¥ã€‚

Exp4 â€” SVM (RBF)ï¼ˆTop-15ï¼Œleak=genderï¼‰
SAFEï¼ˆä¸å«æ€§åˆ«ï¼‰

Val/Testï¼šmacro-F1 0.605/0.616ï¼›bAcc 0.663/0.672ï¼›OvR AUC 0.783/0.795

æ¨¡å¼ï¼šGood å¬å›å¾ˆé«˜ï¼ˆVal ~0.78ï¼‰ï¼ŒStandard å¬å›ä½ï¼ˆ~0.49ï¼‰ï¼Œæ•´ä½“å®å¹³å‡ä¸‹é™ã€‚

LEAKï¼ˆä»…åŠ å…¥ genderï¼‰

CV best macro-F1 â‰ˆ 0.606ï¼ˆâ‰¤ SAFE 0.611ï¼‰ â†’ å‡ ä¹æ— ç¨³å®šæ”¶ç›Šï¼Œä½†å¼•å…¥å…¬å¹³æ€§é£é™©ã€‚

ç»“è®ºï¼šgender ä¸å¸¦æ¥å¯é æå‡ï¼Œä¸”å­˜åœ¨åˆè§„/ä¼¦ç†é—®é¢˜ï¼Œä¸çº³å…¥ç”Ÿäº§ï¼›å…¬å¹³æ€§å¯åœ¨ç›‘æ§å±‚é¢ç”¨ reweighing æˆ– group-wise thresholds å¤„ç†ã€‚

What the rubric wants & how we meet it / ä¸è¯„åˆ†æ ‡å‡†é€æ¡å¯¹é½
1) Pertinence & scientific experimentation / å®éªŒè®¾è®¡ä¸ç§‘å­¦æ€§

æ¸…æ™°å¯¹ç…§ï¼šæ¯ä¸ªå®éªŒéƒ½æœ‰å”¯ä¸€çš„å¯¹ç…§å˜é‡ï¼ˆExp2=credit_mixï¼›Exp3=ç­–ç•¥å˜é‡ï¼›Exp4=genderï¼‰ã€‚

é‡åŒ–å½±å“ï¼šå¯¹ Exp2/3 æŠ¥å‘Šæ•°å€¼åŒ– upliftï¼ˆExp2ï¼šmacro-F1 +0.03ï¼›Exp3ï¼šCV +~0.02ï¼‰ï¼ŒExp4 æŒ‡å‡ºæ— æ”¶ç›Šã€‚

åˆç†ç»“è®ºï¼šæ›´é«˜åˆ†æ•°â‰ æ›´å¯éƒ¨ç½²ï¼›æ³„æ¼ä¸å…¬å¹³æ€§ä¼˜å…ˆçº§é«˜äºæŒ‡æ ‡æå‡ã€‚

2) Model justification & hyperparameters / æ¨¡å‹é€‰æ‹©ä¸è°ƒå‚

RFï¼šbagging æŠ‘åˆ¶æ–¹å·®ã€åœ¨ä¸å‡è¡¡å¤šç±»ä»»åŠ¡ä¸Šæ›´ç¨³ï¼ˆclass_weight='balanced'ï¼‰ï¼ŒTop-20 ç‰¹å¾å¯è§£é‡Šä¸”æ•ˆç‡é«˜ã€‚

HGBï¼šboosting æ•æ‰éçº¿æ€§æ®‹å·®ï¼Œæ ¡å‡†æ›´å¥½ï¼Œé€‚åˆé˜ˆå€¼å†³ç­–ã€‚

SVMï¼šæ ¸æ–¹æ³•æé«˜ Good å¬å›ï¼Œä½†æ•´ä½“å®å¹³å‡ä¸‹é™ï¼Œä½œä¸ºå¯¹ç…§å¾ˆæœ‰ä»·å€¼ã€‚

è°ƒå‚ç­–ç•¥ï¼šRandomized â†’ Grid â†’ Narrowï¼›æœ€åä»¥ç¨³å®šæ€§ + ç®€å•ä¼˜å…ˆå®šç‰ˆï¼ˆRF ä¾‹ï¼šmax_depthâ‰ˆ16â€“17, leaf=3, sqrt, n_estimatorsâ‰ˆ400â€“500ï¼‰ã€‚

3) Ethics & privacy / ä¼¦ç†ä¸éšç§ï¼ˆå« Indigenous/å—ä¼—åæ€ï¼‰

credit_mixï¼šå‡†æ ‡ç­¾é£é™©ï¼ˆå¯èƒ½æ¥æºäºå†…éƒ¨è¯„çº§/ç­–ç•¥æ˜ å°„ï¼‰ï¼›éœ€è°¨æ…ä½¿ç”¨æˆ–ä»…ä¿ç•™è½¬æ¢/äº¤äº’ç‰ˆã€‚

interest_rate/limit_changeï¼šç­–ç•¥åŒæº â†’ æ˜ç¡®ä¿¡æ¯æ³„æ¼ï¼›ä¸å¯ç”¨äºéƒ¨ç½²ã€‚

genderï¼šç¾¤ä½“å…¬å¹³æ€§é£é™©ï¼›ä¸çº³å…¥ç”Ÿäº§æ¨¡å‹ï¼›å»ºè®®åˆ†ç»„é˜ˆå€¼/ç›‘æ§ä¸é€æ˜è¯´æ˜ã€‚

å—å½±å“æ–¹ï¼šå®¢æˆ·ï¼ˆå°¤å…¶å¥³æ€§æˆ–ç‰¹å®šç¾¤ä½“ï¼‰ã€ä¿¡è´·åˆè§„å›¢é˜Ÿã€ä¸šåŠ¡é£é™©ä¸å“ç‰Œã€‚

å»ºè®®ï¼šä¸Šçº¿ SAFE ç‰¹å¾é›†ï¼›å®šæœŸåš drift/PSIã€å…¬å¹³æ€§æŒ‡æ ‡ï¼ˆæŒ‰æ€§åˆ«/åœ°åŒºç­‰ï¼‰ç›‘æ§ã€‚

4) Communication & visuals / æ²Ÿé€šä¸å¯è§†åŒ–

æ¨èå›¾è¡¨ï¼š

å¯¹ç…§æ¡å½¢å›¾ï¼šå±•ç¤º Exp2/3 SAFE vs LEAK çš„ Macro-F1 / bAcc upliftï¼›

HGB calibration curveï¼ˆå¯ä¿¡åº¦ï¼‰ï¼›

PDP/SHAPï¼šoutstanding_debt, dti, min_amount_paymentï¼›

Learning curveï¼ˆRF/HGB æ”¶æ•›ï¼‰ã€‚

Final decision & deployment plan / æœ€ç»ˆé€‰æ‹©ä¸è½åœ°å»ºè®®

Final pick / æœ€ç»ˆæ¨¡å‹ï¼šRF-SAFE (Top-20)

ä»£è¡¨æ€§é…ç½®ï¼šn_estimators=500, max_depth=17, min_samples_leaf=3, max_features='sqrt', class_weight='balanced'

é€‰æ‹©ç†ç”±ï¼šæœ€å‡è¡¡ï¼ˆGood/Poor å¬å›é«˜ã€Standard å¬å›ä¸è‡³äºå¡Œé™·ï¼‰ã€ç¨³å®šï¼ˆç§å­æ³¢åŠ¨å°ï¼‰ã€é«˜å¯è§£é‡Š/é«˜æ•ˆç‡ã€‚

Companion / ä¼´éšæ¨¡å‹ï¼šHGB-SAFE

ç”¨é€”ï¼šå½“éœ€è¦å¯é æ¦‚ç‡ï¼ˆé˜ˆå€¼ç­–ç•¥/åˆ†å±‚å®šä»·ï¼‰æˆ–æå‡ Good å¬å›æ—¶åšå‚è€ƒï¼›ä¹Ÿå¯ä¸ RF è½¯æŠ•ç¥¨ã€‚

Operating policy / è¿è¡Œç­–ç•¥

é˜ˆå€¼è°ƒä¼˜ï¼šåœ¨éªŒè¯é›†æ‰«ææ¯ç±»é˜ˆå€¼ï¼ˆç‰¹åˆ«æ˜¯ Good/Poorï¼‰ï¼Œåœ¨æµ‹è¯•é›†å›ºåŒ–ã€‚

ç›‘æ§ï¼šæ¯æœˆè·Ÿè¸ª macro-F1ã€bAccã€per-class recallã€PSI ä¸ å…¬å¹³æ€§æŒ‡æ ‡ï¼›å¼‚å¸¸è§¦å‘å†è®­ç»ƒã€‚

æ²»ç†ï¼šç¦æ­¢ä½¿ç”¨ç­–ç•¥åŒæºå˜é‡ä¸æ€§åˆ«å˜é‡ï¼›credit_mix å¦‚éœ€ä¿ç•™ï¼Œä»…ç”¨æœ‰åº/äº¤äº’çš„â€œå®‰å…¨ç‰ˆæœ¬â€ã€‚

One-paragraph conclusionï¼ˆå¯ç›´æ¥è´´å…¥æŠ¥å‘Šç»“å°¾ï¼‰

EN:
With the corrected ablations, each experiment isolates a single risk factor: credit_mix (Exp2), strategy-derived variables (Exp3), and gender (Exp4). The ablations quantify how quasi-label or policy artifacts can artificially inflate metrics, while gender brings fairness concerns without robust gains. The RF-SAFE model with a compact, interpretable feature set offers the best balance of accuracy and stability; HGB-SAFE provides better calibration for policy thresholds. We recommend deploying RF-SAFE with calibrated thresholds and continuous fairness/shift monitoring, and using HGB-SAFE as a complementary probability estimator.

è¡¥å……ä¸€ä¸‹å¯¹äºleakç‰¹å¾ç†è§£é”™è¯¯çš„å®éªŒæ‘˜è¦å’Œå®éªŒæ€»ç»“ï¼ˆå¦‚æœ‰å†²çªä»¥ä¿®æ­£åçš„å†…å®¹ä¸ºå‡†ï¼‰ï¼š

1) Executive Summary / æ‰§è¡Œæ‘˜è¦

EN (short):
Across four experiments on multi-class credit rating (Good/Standard/Poor), ensemble tree models performed best. Random Forest with top-20 interpretable features was the most balanced and stable (Val/Test macro-F1 â‰ˆ 0.639/0.639, bAcc â‰ˆ 0.668/0.664). Histogram Gradient Boosting matched RF on test (~0.646 macro-F1) and offered better probability calibration. SVM maximized minority (Good) recall but hurt Standard recall and overall macro-F1. Controlled â€œleakageâ€ (using cc_interest_rate/credit_limit_change) inflated macro-F1 by ~+0.03 but is not deployable. Gender brought ethical risks with little robust gain.

ä¸­æ–‡ï¼ˆç®€è¦ï¼‰ï¼š
åœ¨å››ç»„å®éªŒä¸­ï¼Œé›†æˆæ ‘æ¨¡å‹æ•ˆæœæœ€ä½³ã€‚åŸºäº Top-20 å¯è§£é‡Šç‰¹å¾ çš„ éšæœºæ£®æ—æœ€ç¨³å¥ï¼ˆéªŒè¯/æµ‹è¯• macro-F1 çº¦ 0.639/0.639ï¼ŒbAcc çº¦ 0.668/0.664ï¼‰ã€‚HGB æµ‹è¯•é›†è¾¾åˆ° ~0.646 macro-F1ï¼Œå¹¶æä¾›æ›´å¥½çš„æ¦‚ç‡æ ¡å‡†ã€‚SVM å¼ºåŒ–äº†å°‘æ•°ç±»ï¼ˆGoodï¼‰å¬å›ï¼Œä½†ç‰ºç‰²äº† Standard ç±»ä¸æ€»ä½“ macro-F1ã€‚ä½¿ç”¨ç–‘ä¼¼æ³„æ¼å˜é‡ï¼ˆcc_interest_rate/credit_limit_changeï¼‰å¯æŠŠåˆ†æ•°æ¨é«˜ â‰ˆ+0.03ï¼Œä½†ä¸å…·å¯éƒ¨ç½²æ€§ï¼›gender å­˜åœ¨å…¬å¹³æ€§é£é™©ï¼Œæ”¶ç›Šæœ‰é™ã€‚

2) Experimental Setup Summary / å®éªŒè®¾ç½®æ¦‚è§ˆ

Data split / åˆ’åˆ†ï¼šåˆ†å±‚ 70/15/15ï¼ˆtrain/val/testï¼‰ï¼Œç¡®ä¿å¯ç”¨äº CVã€‚

Targetï¼šcredit_ratingï¼ˆGood / Standard / Poorï¼‰ï¼Œç±»åˆ«ä¸å‡è¡¡ï¼ˆçº¦ 18% / 53% / 29%ï¼‰ã€‚

Metrics / æŒ‡æ ‡ï¼šMacro-F1ï¼ˆä¸»ï¼‰ã€Balanced Accuracyã€ï¼ˆè¡¥å……ï¼‰OvR ROC-AUCã€‚

Feature policy / ç‰¹å¾ç­–ç•¥ï¼šå‰”é™¤ PIIï¼›é‡‡ç”¨å¯è§£é‡Šã€ä¸šåŠ¡ç›¸å…³çš„æ•°å€¼/ç±»åˆ«ç‰¹å¾ï¼›æ„é€  log1p__ é‡‘é¢ã€dtiã€emi_to_income ç­‰ï¼›OHE åå¯¹ credit_mix*/gender* è¿›è¡Œå¯¹ç…§å‰”é™¤ï¼›ä¸å¼•å…¥å·²çŸ¥ç­–ç•¥å˜é‡ï¼ˆåˆ©ç‡ã€é¢åº¦è°ƒæ•´ï¼‰ä½œä¸ºæœ€ç»ˆæ¨¡å‹ç‰¹å¾ã€‚

Imbalanceï¼šæ ‘æ¨¡å‹ç”¨ class_weight="balanced"ï¼›HGB ç”¨ sample_weightï¼›SVM åŒæ ·ä½¿ç”¨ class_weight="balanced"ã€‚

3) Results by Experiment / åˆ†å®éªŒç»“æœ
Exp1 â€” Decision Treeï¼ˆéçº¿æ€§å¯è§£é‡ŠåŸºçº¿ï¼‰

Best params: max_depth=6, min_samples_leaf=1, min_samples_split=2
Val: macro-F1 0.628, bAcc 0.646
Test: macro-F1 0.638, bAcc 0.650

EN: Simple, interpretable non-linear baseline. Strong recall for Poor (â‰ˆ0.75), moderate for Good (â‰ˆ0.56), lower for Standard.
CNï¼š ç®€å•å¯è§£é‡Šçš„éçº¿æ€§åŸºçº¿ã€‚Poor å¬å›é«˜ï¼ˆ~0.75ï¼‰ï¼ŒGood ä¸­ç­‰ï¼ˆ~0.56ï¼‰ï¼ŒStandard åä½ã€‚ä¸ºåç»­é›†æˆå­¦ä¹ æä¾›äº†æ¸…æ™°èµ·ç‚¹å’Œé‡è¦æ€§å‚è€ƒã€‚

Exp2 â€” Random Forestï¼ˆTop-20 å¯è§£é‡Šç‰¹å¾ + å¯¹ç…§/æ³„æ¼æ£€éªŒï¼‰

Search & fine-tune:

Randomized â†’ Grid â†’ Narrow gridï¼›ç¨³å®šå‚æ•°ï¼š
n_estimators=500, max_depth=17, min_samples_leaf=3, max_features='sqrt', class_weight='balanced'
Stability check: å¤šéšæœºç§å­æ³¢åŠ¨å°ï¼ˆÎ” macro-F1 â‰ˆ 0.003ï¼‰ã€‚

SAFEï¼ˆæ— æ³„æ¼/æ— æ•æ„Ÿï¼‰

Val: macro-F1 0.639, bAcc 0.668

Test: macro-F1 0.639, bAcc 0.664

Per-class (Val)ï¼šGood 0.68 R, Poor 0.73 R, Standard 0.60 Rï¼›Precision å¯¹ Standard æ›´é«˜ï¼ˆè°¨æ…é¢„æµ‹ï¼‰ã€‚

LEAKï¼ˆå« cc_interest_rate + credit_limit_changeï¼‰

Val: macro-F1 0.670, bAcc 0.711

Test: macro-F1 0.668, bAcc 0.703

Observation / ç°è±¡ï¼šåˆ†æ•°æ˜¾è‘—æå‡ï¼Œä½†æœ¬è´¨ä¸Šâ€œå­¦ä¹ äº†é“¶è¡Œç­–ç•¥â€ï¼Œä¿¡æ¯æ³„æ¼é£é™©å¤§ï¼Œä¸å¯éƒ¨ç½²ã€‚

Top featuresï¼ˆSAFEï¼‰ï¼ˆä¸€è‡´æ€§å¼ºï¼‰ï¼š
log1p__outstanding_debt, min_amount_payment_Yes, avg_days_past_due, credit_history_years, dti, count_credit_inquiries, count_delayed_payment, count_bank_accounts, log1p__annual_income, emi_to_income â€¦
Interpretation / è§£é‡Šï¼šå€ºåŠ¡æ°´å¹³ã€é€¾æœŸå¤©æ•°ã€æ˜¯å¦ä»…ä»˜æœ€ä½è¿˜æ¬¾ã€ä¿¡ç”¨å†å²å¹´é™ä¸è¯„çº§å¼ºç›¸å…³ï¼Œç¬¦åˆä¿¡ç”¨ä¸šåŠ¡å¸¸è¯†ã€‚

Exp3 â€” Histogram Gradient Boostingï¼ˆHGBï¼Œå»¶ç»­ Top-20 + æ³„æ¼å¯¹ç…§ï¼‰

Randomized & Gridï¼ˆSAFEï¼‰ï¼š

CV best ~ 0.632ï¼Œæœ€ç»ˆ Val 0.630, Test 0.646ï¼ˆbAcc ~0.682ï¼‰

Minority recallï¼šGood ~0.72, Poor ~0.74ï¼›Standard recall è¾ƒä½ï¼Œä½† Precision æ›´é«˜ï¼ˆæ›´â€œä¿å®ˆâ€ï¼‰ã€‚

Calibration & PDPï¼ˆè¡¥å……åˆ†æå»ºè®®ï¼‰ï¼šæ¦‚ç‡æ›´å¹³æ»‘ã€PDP æ˜¾ç¤ºå€ºåŠ¡ä¸ DTI çš„éçº¿æ€§å½±å“ï¼Œè§£é‡Šæ€§è¾ƒå¼ºã€‚

LEAKï¼ˆå«ç­–ç•¥å˜é‡ï¼‰ï¼š

Randomized best CV ~0.654 â†’ åŒæ ·æ˜¾ç¤ºâ€œæ³„æ¼å¢ç›Šâ€ï¼Œä¸å¯ç”¨äºç”Ÿäº§ã€‚

Conclusion / å°ç»“ï¼šHGB ä¸ RF è¡¨ç°ç›¸è¿‘ï¼ŒHGB æ¦‚ç‡æ ¡å‡†æ›´å¥½ï¼Œå¯¹ minority recall æ›´ç§¯æï¼›RF æ›´å‡è¡¡ç¨³å¥ã€‚

Exp4 â€” SVM (RBF)ï¼ˆTop-15 ç‰¹å¾ + æ€§åˆ«å…¬å¹³æ€§å¯¹ç…§ï¼‰

Best params: C=1, gamma=0.2, class_weight='balanced'
SAFEï¼š

Val: macro-F1 0.605, bAcc 0.663, OvR AUC 0.783

Test: macro-F1 0.616, bAcc 0.672, OvR AUC 0.795

Patternï¼šGood å¬å›å¾ˆé«˜ï¼ˆVal ~0.78ï¼‰ï¼Œä½† Standard å¬å›åä½ï¼ˆ~0.49ï¼‰ï¼Œæ•´ä½“å®å¹³å‡ä¸‹é™ã€‚

LEAK (gender å¯¹ç…§)ï¼š

CV best ~0.606ï¼›åŠ å…¥ gender å¹¶æ— ç¨³å®šçš„æ€»ä½“æå‡ï¼Œå´å¼•å…¥å…¬å¹³æ€§é£é™©ï¼ˆæ½œåœ¨ç¾¤ä½“åç½®ï¼‰ã€‚

Conclusion / å°ç»“ï¼šSVM æ“…é•¿ minority recallï¼Œä½†æŸå¤± majority å¹³è¡¡ï¼›ä¸ä½œä¸ºæœ€ç»ˆæ–¹æ¡ˆï¼Œå¯ä½œä¸ºé£é™©åå¥½æ›´æ¿€è¿›åœºæ™¯çš„å¤‡é€‰ã€‚

4) Cross-Experiment Insights / è·¨å®éªŒæ´è§ï¼ˆå¯¹ç…§ + ä¼¦ç†ï¼‰
Leakage controls / æ³„æ¼å¯¹ç…§ç»“è®º

æ·»åŠ  cc_interest_rate ä¸ credit_limit_change ä¼šæ˜¾è‘—æŠ¬é«˜ macro-F1ï¼ˆRF: 0.639 â†’ 0.670ï¼›HGB: ~0.63 â†’ ~0.65ï¼‰ã€‚

è§£é‡Šï¼šè¿™ä¸¤è€…åæ˜ é“¶è¡Œå†…éƒ¨é£é™©å®šä»·/é¢åº¦ç­–ç•¥ï¼Œä¸ credit_rating åŒæºï¼Œæ¨¡å‹å­¦ä¹ åˆ°â€œç­–ç•¥æ·å¾„â€è€ŒéçœŸå®ä¿¡ç”¨è¡Œä¸ºã€‚

ç»“è®ºï¼šä¸å¯ç”¨äºç”Ÿäº§ï¼Œä»…ç”¨äºç ”ç©¶å¯¹ç…§ï¼›æŠ¥å‘Šä¸­è¯´æ˜â€œhigher accuracy â‰  reliable generalizationâ€ã€‚

Fairness reflection / å…¬å¹³æ€§åæ€

gender åœ¨ SVM å¯¹ç…§ä¸­æ²¡æœ‰ç¨³å®šæ”¶ç›Šï¼Œå´å¯èƒ½å¯¼è‡´ç¾¤ä½“ä¸å…¬å¹³ï¼ˆä¸åŒæ€§åˆ«å¬å›/è¯¯æŠ¥å·®å¼‚ï¼‰ã€‚

ç»“è®ºï¼šä¸çº³å…¥ç”Ÿäº§ç‰¹å¾ï¼›å»ºè®®åç»­ä½¿ç”¨å»åæ–¹æ³•ï¼ˆå¦‚ reweightingã€group thresholdsï¼‰åšç›‘æ§ä¸æ ¡æ­£ã€‚

Feature policy / ç‰¹å¾ç­–ç•¥

RF/HGB çš„é‡è¦æ€§æ’åºä¸€è‡´æ€§é«˜ï¼Œè¯´æ˜ä¸¤ç±»æ¨¡å‹ä¾èµ–çš„æ ¸å¿ƒä¿¡å·ç¨³å®šï¼Œå¯è§£é‡Šæ€§å¼ºã€‚

credit_mix å¯ä¿ç•™â€œå®‰å…¨ç‰ˆæœ¬â€ï¼ˆæœ‰åºç¼–ç æˆ–ä¸ DTI çš„äº¤äº’ï¼‰ï¼Œä½†é¿å…å…¶æˆä¸ºâ€œå‡†æ ‡ç­¾â€ã€‚åœ¨æœ¬é¡¹ç›®ä¸­æˆ‘ä»¬å·²é‡‡ç”¨å®‰å…¨é›†ä¸ºä¸»ã€‚

5) Business Impact & Decision / ä¸šåŠ¡å½±å“ä¸å†³ç­–å»ºè®®

EN:

Identify prime (Good): RF/HGB significantly improved recall vs baseline, enabling better cross-sell/limit increase decisions; HGB is slightly more aggressive for Good recall.

Control risk (Poor): Both RF and HGB maintain high recall for Poor, reducing credit loss.

Standard class: RF is more balanced (higher recall than HGB/SVM), thus better for day-to-day risk management.

Final pick: RF (Top-20, SAFE) as the primary model, HGB as a calibrated companion (probability outputs for policy thresholds).

ä¸­æ–‡ï¼š

ä¼˜è´¨å®¢æˆ·è¯†åˆ«ï¼ˆGoodï¼‰ï¼šRF/HGB æ˜æ˜¾æå‡ Good å¬å›ï¼Œæœ‰åŠ©äºé¢åº¦æå‡ä¸ä¸ªæ€§åŒ–è¥é”€ï¼›HGB åœ¨ Good ä¸Šç•¥æ›´ç§¯æã€‚

é«˜é£é™©æ§åˆ¶ï¼ˆPoorï¼‰ï¼šä¸¤è€…å¯¹ Poor çš„å¬å›ç¨³å®šï¼Œé™ä½ä¸è‰¯é£é™©ã€‚

æ ‡å‡†å®¢æˆ·ï¼ˆStandardï¼‰ï¼šRF æ›´å‡è¡¡ï¼Œé€‚åˆå¸¸è§„é£æ§åœºæ™¯ã€‚

æœ€ç»ˆæ¨èï¼šä»¥ RFï¼ˆTop-20ï¼Œå®‰å…¨ç‰¹å¾é›†ï¼‰ ä¸ºä¸»æ¨¡å‹ï¼›HGB ä½œä¸ºæ¦‚ç‡æ›´ç¨³çš„æ ¡å‡†æ¨¡å‹ï¼ˆç”¨äºé˜ˆå€¼ç­–ç•¥/åˆ†å±‚å®šä»·ï¼‰ã€‚

6) Reproducibility & Error Sources / å¯å¤ç°æ€§ä¸è¯¯å·®æ¥æº

EN:

Fixed 70/15/15 split; StratifiedKFold=5 with a fixed seed for CV comparability.

Small metric differences (â‰¤0.003 macro-F1) across nearby RF settings are within CV variance.

Potential errors: mild label noise, synthetic data patterns, and overlapping class boundaries (seen in Standard vs others).
CNï¼š

å›ºå®šåˆ†å±‚åˆ’åˆ†ä¸ CV éšæœºç§å­ï¼Œä¿è¯å¯æ¯”æ€§ï¼›

RF ç›¸é‚»è®¾ç½®å·®å¼‚ â‰¤0.003 å±äº CV æ–¹å·®èŒƒå›´ï¼›

æ½œåœ¨è¯¯å·®æ¥æºï¼šæ ‡ç­¾å™ªå£°ã€åˆæˆæ•°æ®æ¨¡å¼ã€ç±»é—´è¾¹ç•Œé‡å ï¼ˆStandard æ›´æ˜æ˜¾ï¼‰ã€‚

7) Final Model & Operating Policy / æœ€ç»ˆæ¨¡å‹ä¸ç­–ç•¥

Chosen model / æœ€ç»ˆæ¨¡å‹ï¼šRandom Forest (SAFE, Top-20)
n_estimators=500, max_depth=17, min_samples_leaf=3, max_features='sqrt', class_weight='balanced'

Operating policy / è¿è¡Œç­–ç•¥ï¼ˆå»ºè®®ï¼‰

Thresholds / é˜ˆå€¼ï¼šæŒ‰ä¸šåŠ¡åå¥½åœ¨éªŒè¯é›†åšé˜ˆå€¼æ‰«æï¼ˆå¯¹ Good/Poor çš„ class-wise æ¦‚ç‡é˜ˆå€¼ï¼‰ï¼Œåœ¨æµ‹è¯•é›†å›ºåŒ–ã€‚

Score bands / è¯„åˆ†åˆ†å±‚ï¼šå°†é¢„æµ‹æ¦‚ç‡åˆ†å±‚ï¼ˆå¦‚ Low/Med/High riskï¼‰è¾“å‡ºï¼Œä¾¿äºäº§å“ç­–ç•¥è½åœ°ã€‚

Monitoring / ç›‘æ§ï¼šæ¯æœˆè·Ÿè¸ª macro-F1ã€per-class recallã€PSIï¼ˆäººå£ç¨³å®šæ€§æŒ‡æ ‡ï¼‰ä¸ fairness æŒ‡æ ‡ï¼ˆæ€§åˆ«/åœ°åŒºç­‰ï¼‰ã€‚

Fallback / å…œåº•ï¼šå½“å¤–éƒ¨åˆ†å¸ƒæ¼‚ç§»æˆ–ç›‘ç®¡è¦æ±‚å¢å¼ºæ—¶ï¼Œå¯åˆ‡æ¢åˆ° HGBï¼ˆæ ¡å‡†æ›´ä½³ï¼‰æˆ–å¯ç”¨ RF+HGB è½¯æŠ•ç¥¨åšç¨³å®šåŒ–ã€‚

8) What else for HD / è¿›ä¸€æ­¥æ‹‰æ»¡è¯„åˆ†çš„å°ç‚¹

Calibration curve & reliability diagramï¼ˆHGB æ¦‚ç‡å¯ä¿¡åº¦å›¾ï¼‰

Partial dependence / SHAPï¼ˆå±•ç¤º outstanding_debt, dti, min_amount_payment çš„å•è°ƒ/éçº¿æ€§å…³ç³»ï¼‰

Learning curveï¼ˆRF/HGB æ”¶æ•›å›¾ï¼Œè¯æ˜â€œæ›´å¤šæ•°æ®æ”¶ç›Šæœ‰é™â€ï¼‰

Compact appendix codeï¼ˆå±•ç¤ºä½ å¦‚ä½•åšé˜ˆå€¼æ‰«æå’Œå¯¹ç…§è¯•éªŒçš„å¯å¤ç°è„šæœ¬ï¼‰

One-paragraph Conclusion / ä¸€æ®µå¼ç»“è®ºï¼ˆå¯ç›´æ¥æ”¾æŠ¥å‘Šç»“å°¾ï¼‰

EN:
The experimentation demonstrates a clear progression from a simple interpretable baseline (Decision Tree) to robust ensembles (Random Forest, HGB) and a kernel method (SVM). Random Forest with a compact, interpretable feature set provides the best balance of accuracy (macro-F1 â‰ˆ 0.64), stability, and operational simplicity. HGB delivers comparable accuracy with better probability calibration, making it a strong companion for threshold-based policies. Leakage and fairness ablations show that strategy-driven or demographic features can inflate metrics but undermine deployability. We therefore recommend deploying the RF-SAFE model with calibrated thresholds and continuous monitoring, and retaining HGB for probability calibration and policy sensitivity analyses.

ä¸­æ–‡ï¼š
æœ¬é¡¹ç›®å½¢æˆäº†ä»å¯è§£é‡ŠåŸºçº¿åˆ°é›†æˆä¸æ ¸æ–¹æ³•çš„æ¸…æ™°é€’è¿›ã€‚é‡‡ç”¨ Top-20 å¯è§£é‡Šç‰¹å¾ çš„ éšæœºæ£®æ—åœ¨å‡†ç¡®æ€§ã€ç¨³å®šæ€§ä¸è½åœ°å¤æ‚åº¦ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ï¼ˆmacro-F1 çº¦ 0.64ï¼‰ã€‚HGB æä¾›ç›¸è¿‘å‡†ç¡®ç‡å¹¶å…·æ›´ä½³çš„æ¦‚ç‡æ ¡å‡†ï¼Œé€‚åˆä½œä¸ºé˜ˆå€¼ç­–ç•¥çš„è¾…åŠ©æ¨¡å‹ã€‚å¯¹ç…§å®éªŒè¡¨æ˜ï¼šå°†ç­–ç•¥/äººå£ç‰¹å¾çº³å…¥æ¨¡å‹è™½èƒ½æå‡åˆ†æ•°ï¼Œä½†ä¼šå‰Šå¼±å¯éƒ¨ç½²æ€§ä¸å…¬å¹³æ€§ã€‚å› æ­¤å»ºè®®ä¸Šçº¿ RF-SAFEï¼Œé…åˆé˜ˆå€¼æ ¡å‡†ä¸æŒç»­ç›‘æ§ï¼Œå¹¶ä¿ç•™ HGB ç”¨äºæ¦‚ç‡æ ‡å®šä¸ç­–ç•¥æ•æ„Ÿæ€§åˆ†æã€‚

ä»¥ä¸‹æ˜¯reportçš„æ¨¡æ¿å†…å®¹ï¼š
Classification Models

Business Understanding 

Business Use Cases 

Describe the specific business use cases or scenarios where the project is applied. 

Discuss the challenges or opportunities that motivated the project. 

Instructions: Describe the business use cases or scenarios where the project is applied. Discuss the challenges or opportunities that motivated the project, explaining why machine learning algorithms are relevant in this context. 

Key Objectives 

Specify the key objectives or goals of the project. 

Identify the stakeholders and their requirements. 

Explain how the project aims to address these requirements. 

Instructions: Specify the key objectives or goals of the project, highlighting the desired outcomes. Identify the stakeholders involved and their specific requirements. Explain how the project aims to address these requirements through the use of machine learning algorithms.

Data Understanding 

Provide insights into the dataset used for the project. 

Describe the data sources, data collection methods, and any data limitations. 

Discuss the target variable and the features present in the dataset and their significance. 

Instructions: Describe the dataset used for the project, including its sources and any limitations. Discuss the variables or features present in the dataset and their relevance to the project. Include any exploratory data analysis conducted to understand the data better.

Data Preparation 

Describe the steps taken to prepare the data for modeling. 

Discuss the data cleaning, preprocessing, and feature engineering techniques applied. 

Explain the rationale for data splitting strategy used. 

Document any handling of missing values, outliers, or imbalanced data. 

Instructions: Describe the data preparation steps taken before modelling. Include details about data cleaning, preprocessing, and feature engineering techniques applied. Explain how missing values, outliers, or imbalanced data were handled and any transformations performed on the dataset. Provide clear explanations on data splitting strategy. 

Modeling 

Describe the machine learning algorithms used for modeling. 

Discuss the rationale behind selecting these algorithms. 

Explain the parameter tuning and model selection process. 

Instructions: Describe the machine learning algorithms used for modeling, providing a rationale for their selection based on the project goals. Explain the process of parameter tuning and model selection. Include details about the algorithms' implementation and any considerations made during the modeling phase.

Evaluation 

Results and Analysis 

Present the results of the model evaluation, including accuracy, precision, recall, F1-score, etc. 

Analyze and compare the performance of each model. 

Discuss the key insights gained during the experimentation phases. 

Instructions: Present the results of the model evaluation, including accuracy, precision, recall, F1-score, or any other relevant metrics. Analyze and compare the performance of each model, highlighting the key insights gained during the experimentation phases. Discuss the implications of these insights on the project's goals and potential areas for further improvement.

Business Impact and Benefits 

Assess the impact and benefits of the final model on the business use cases. 

Discuss how the model contributes to solving the identified challenges or exploiting opportunities. 

Quantify the improvements achieved and the potential value generated. 

Instructions: Assess and discuss the impact and benefits of the final model on the identified business use cases. Explain how the model contributes to solving the identified challenges or exploiting opportunities. Quantify the improvements achieved and discuss the potential value generated by the model.

Data Privacy and Ethical Concerns 

Assess the data privacy implications of the project. 

Discuss any ethical concerns related to data collection, usage, or model deployment. 

Address steps taken to ensure data privacy and ethical considerations. 

Assess potential negative impacts and risks for Indigenous people  

Instructions: Assess the data privacy implications of the project, considering any sensitive information or privacy concerns related to data collection, usage, or model deployment. Discuss any ethical concerns and considerations. Address the steps taken to ensure data privacy and mitigate ethical concerns. 

Conclusion 

Summarize the key findings, insights, and outcomes of the project. 

Reflect on the project's success in achieving its goals and meeting stakeholders' requirements. 

Discuss any future work, recommendations, or next steps based on the project's outcomes. 

Instructions: Summarize the key findings, insights, and outcomes of the project. Reflect on the project's success in achieving its goals and meeting stakeholders' requirements. Discuss any future work, recommendations, or next steps based on the project's outcomes.