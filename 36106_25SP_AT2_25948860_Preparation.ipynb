{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6wc2HE0pke"
      },
      "source": [
        "# **Preparation Notebook**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVpE17Ahezu"
      },
      "source": [
        "---\n",
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "S8jFaNXqvV5W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] 拒绝访问。: 'C:\\\\Users\\\\brohao\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\~-~earn\\\\.libs\\\\msvcp140.dll'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You can now save your data files in: c:\\Users\\brohao\\Desktop\\UTS\\36106\\ClassificationModels-36106-AT2\\36106\\assignment\\AT2\\data\n"
          ]
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "!pip install -q utstd\n",
        "\n",
        "from utstd.folders import *\n",
        "from utstd.ipyrenders import *\n",
        "\n",
        "at = AtFolder(\n",
        "    course_code=36106,\n",
        "    assignment=\"AT2\",\n",
        ")\n",
        "at.run()\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujC3TjlB7-EZ"
      },
      "source": [
        "---\n",
        "## Student Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dug0CHu27_wW"
      },
      "outputs": [],
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "student_name = \"Jiayu Hao\"\n",
        "student_id = \"25948860\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SeSMrvjD8AIX"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">student_name</p><h1 font-size: 3em>Jiayu Hao</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='student_name', value=student_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Utiw0TD68JjD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">student_id</p><h1 font-size: 3em>25948860</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='student_id', value=student_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO3Cb4F0DrGN"
      },
      "source": [
        "---\n",
        "## 0. Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgTrMfyylVLf"
      },
      "source": [
        "### 0.a Install Additional Packages\n",
        "\n",
        "> If you are using additional packages, you need to install them here using the command: `! pip install <package_name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "D79tb2V-lVpJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\brohao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\brohao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\brohao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\brohao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\brohao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\brohao\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "!pip install scikit-learn\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXFKfa2tp1ch"
      },
      "source": [
        "### 0.b Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GBEAwdncnlAx"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "import pandas as pd\n",
        "import altair as alt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCwQQFkU3v5"
      },
      "source": [
        "---\n",
        "## A. Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxoimXruuKHc"
      },
      "source": [
        "## A.0 # Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FW-0VWj8304m"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "try:\n",
        "  df = pd.read_csv(at.folder_path / \"credit_rating.csv\")\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E18dcL6C3O-4"
      },
      "source": [
        "### A.1 Approach 1 — Remove PII & non-causal address blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SiroVmhn9_HP"
      },
      "outputs": [],
      "source": [
        "# Choose remove column\n",
        "pii_cols = [\n",
        "    \"customer_id\",\"prefix\",\"full_name\",\"email\",\"phone_number\",\n",
        "    \"secondary_address\",\"building_number\",\"street_name\",\"street_suffix\",\n",
        "    \"city\",\"postcode\",\"state_abbr\",\"dob\",\"cc_number\",\"cc_expiry\",\"cc_security_code\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# provide an explanation on why you use this approach for feature selection and describe its results\n",
        "feature_selection_1_insights = \"\"\"\n",
        "We removed personally identifiable information (PII) and address-related columns \n",
        "because they have no predictive value and may cause privacy or fairness issues. \n",
        "These fields, such as names, emails, and credit card numbers, \n",
        "are unrelated to credit risk and could introduce bias or data leakage. \n",
        "\n",
        "By dropping them, we reduce noise, improve model interpretability, \n",
        "and ensure ethical and regulatory compliance. \n",
        "\n",
        "This step also lowers dimensionality and keeps only business-relevant, \n",
        "reproducible features for modeling.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7JRXCIVFPHlL"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_selection_1_insights</p><h3 font-size: 3em>\n",
              "We removed personally identifiable information (PII) and address-related columns \n",
              "because they have no predictive value and may cause privacy or fairness issues. \n",
              "These fields, such as names, emails, and credit card numbers, \n",
              "are unrelated to credit risk and could introduce bias or data leakage. \n",
              "\n",
              "By dropping them, we reduce noise, improve model interpretability, \n",
              "and ensure ethical and regulatory compliance. \n",
              "\n",
              "This step also lowers dimensionality and keeps only business-relevant, \n",
              "reproducible features for modeling.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_1_insights', value=feature_selection_1_insights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0WdHbsf3vTm"
      },
      "source": [
        "### A.2 Approach 2 — Leakage / quasi-labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2aAKCI6v3xbC"
      },
      "outputs": [],
      "source": [
        "# Choose leakage and sensitive column\n",
        "potential_leak_cols = [\n",
        "    \"cc_interest_rate\",     # leakage\n",
        "    \"credit_limit_change\",  # leakage\n",
        "    \"credit_mix\",           # leakage\n",
        "    \"gender\" # sensitive\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ZETRSFpiPlYL"
      },
      "outputs": [],
      "source": [
        "# provide an explanation on why you use this approach for feature selection and describe its results\n",
        "feature_selection_2_insights = \"\"\"\n",
        "We excluded potential leakage and sensitive columns such as cc_interest_rate, credit_limit_change, \n",
        "credit_mix, and gender to prevent unfair or unrealistic model performance. \n",
        "\n",
        "These variables may contain future or proxy information about the credit rating, \n",
        "or raise ethical and compliance risks. \n",
        "\n",
        "Removing them helps avoid data leakage, reduce redundancy, and ensure the model remains fair, \n",
        "generalizable, and suitable for real business deployment.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "TYTclH9HPlda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_selection_2_insights</p><h3 font-size: 3em>\n",
              "We excluded potential leakage and sensitive columns such as cc_interest_rate, credit_limit_change, \n",
              "credit_mix, and gender to prevent unfair or unrealistic model performance. \n",
              "\n",
              "These variables may contain future or proxy information about the credit rating, \n",
              "or raise ethical and compliance risks. \n",
              "\n",
              "Removing them helps avoid data leakage, reduce redundancy, and ensure the model remains fair, \n",
              "generalizable, and suitable for real business deployment.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_2_insights', value=feature_selection_2_insights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0E3hYLwK-PQ"
      },
      "source": [
        "### A.3 Approach3 — Keep core signals + lightweight context\n",
        "\n",
        "> You can add more cells related to other approaches in this section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "S54DYl_fK7_5"
      },
      "outputs": [],
      "source": [
        "# <Student to fill this section and then remove this comment>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DwaOOhlz_mnJ"
      },
      "outputs": [],
      "source": [
        "base_features = [\n",
        "    # demographics / context\n",
        "    \"age\",\"birth_country\",\"occupation\",\n",
        "    # ability / behavior\n",
        "    \"annual_income\",\"count_bank_accounts\",\"count_credit_cards\",\n",
        "    \"loans_count\",\"avg_days_past_due\",\"count_delayed_payment\",\n",
        "    \"count_credit_inquiries\",\"outstanding_debt\",\"credit_ratio\",\n",
        "    \"count_credit_history_years\",\"monthly_emi_payment\",\"min_amount_payment\",\n",
        "    \"_monthly_invested_amount\",\"payment_behaviour\",\"monthly_balance\",\n",
        "    # low-dimensional loan-type context\n",
        "    \"last_1_loan_type\",\"last_2_loan_type\",\"last_3_loan_type\",\"last_4_loan_type\",\n",
        "    \"last_5_loan_type\",\"last_6_loan_type\",\"last_7_loan_type\",\"last_8_loan_type\",\"last_9_loan_type\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xJ6-jVSE_mxf"
      },
      "outputs": [],
      "source": [
        "# provide an explanation on why you use this approach for feature selection and describe its results\n",
        "feature_selection_3_insights = \"\"\"\n",
        "We kept core behavioral and financial features that show strong separation across credit ratings, \n",
        "along with limited contextual variables for interpretability. \n",
        "These include income, debt, repayment history, and credit inquiries, \n",
        "which directly reflect financial ability and discipline. \n",
        "\n",
        "Context features like occupation, payment behavior, and recent loan types \n",
        "provide useful background without causing leakage. \n",
        "\n",
        "This balanced selection keeps key predictive signals while maintaining model \n",
        "simplicity and business relevance.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "luP391ln_nGt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_selection_3_insights</p><h3 font-size: 3em>\n",
              "We kept core behavioral and financial features that show strong separation across credit ratings, \n",
              "along with limited contextual variables for interpretability. \n",
              "These include income, debt, repayment history, and credit inquiries, \n",
              "which directly reflect financial ability and discipline. \n",
              "\n",
              "Context features like occupation, payment behavior, and recent loan types \n",
              "provide useful background without causing leakage. \n",
              "\n",
              "This balanced selection keeps key predictive signals while maintaining model \n",
              "simplicity and business relevance.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_3_insights', value=feature_selection_3_insights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5bbQlUn3635"
      },
      "source": [
        "### A.z Final Selection of Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_name = \"credit_rating\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zfC-DLKv4AuM"
      },
      "outputs": [],
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "drop_cols = set(pii_cols)\n",
        "features_list = base_features + potential_leak_cols + [target_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "VeRdhcf-K5H4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mainline kept features: 32\n"
          ]
        }
      ],
      "source": [
        "print(\"Mainline kept features:\", len(features_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wRkiZf4sPsxj"
      },
      "outputs": [],
      "source": [
        "# provide a quick explanation on the features selected\n",
        "feature_selection_explanations = \"\"\"\n",
        "The final feature set retains core financial and behavioral variables \n",
        "while removing all PII, address, and sensitive card details to ensure privacy and compliance. \n",
        "Key predictors such as income, debt, repayment history, and credit inquiries are kept, \n",
        "along with limited context features like occupation and recent loan types. \n",
        "The potential_leak_cols are included only to enable controlled comparison experiments \n",
        "without additional preprocessing. \n",
        "This setup preserves relevant business signals, supports fair evaluation, \n",
        "and keeps the data ethically sound and ready for modeling.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "EcG8s40PPs3n"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_selection_explanations</p><h3 font-size: 3em>\n",
              "The final feature set retains core financial and behavioral variables \n",
              "while removing all PII, address, and sensitive card details to ensure privacy and compliance. \n",
              "Key predictors such as income, debt, repayment history, and credit inquiries are kept, \n",
              "along with limited context features like occupation and recent loan types. \n",
              "The potential_leak_cols are included only to enable controlled comparison experiments \n",
              "without additional preprocessing. \n",
              "This setup preserves relevant business signals, supports fair evaluation, \n",
              "and keeps the data ethically sound and ready for modeling.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_explanations', value=feature_selection_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErH_bh604mOe"
      },
      "source": [
        "---\n",
        "## B. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "HrXR7NCLtwxB"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "# Create copy of datasets\n",
        "try:\n",
        "  df_clean = df[features_list].copy()\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bII_PglX5E-r"
      },
      "source": [
        "### B.1 Fixing invalid values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "iaR8p5n8hez4"
      },
      "outputs": [],
      "source": [
        "# Negative overdue days -> 0\n",
        "df_clean[\"avg_days_past_due\"] = df_clean[\"avg_days_past_due\"].clip(lower=0)\n",
        "\n",
        "# Negative EMI -> 0\n",
        "df_clean[\"monthly_emi_payment\"] = df_clean[\"monthly_emi_payment\"].clip(lower=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dNo--8IgPzhl"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to fix this issue and its impacts\n",
        "data_cleaning_1_explanations = \"\"\"\n",
        "Both avg_days_past_due and monthly_emi_payment should be non-negative by definition, \n",
        "as negative values have no business meaning and can mislead the model. \n",
        "Setting negatives to zero corrects data quality issues, makes feature distributions more realistic, \n",
        "and prevents distorted learning from invalid records. \n",
        "This fix improves data integrity and ensures that model behavior aligns with real financial patterns.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cz_yVvA-Pzkz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_1_explanations</p><h3 font-size: 3em>\n",
              "Both avg_days_past_due and monthly_emi_payment should be non-negative by definition, \n",
              "as negative values have no business meaning and can mislead the model. \n",
              "Setting negatives to zero corrects data quality issues, makes feature distributions more realistic, \n",
              "and prevents distorted learning from invalid records. \n",
              "This fix improves data integrity and ensures that model behavior aligns with real financial patterns.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_1_explanations', value=data_cleaning_1_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRJ6Ql1F5ODe"
      },
      "source": [
        "### B.2 Fixing missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "LZwEVfkqLcwe"
      },
      "outputs": [],
      "source": [
        "# Maintain Robustness\n",
        "cat_cols = [c for c in df_clean.columns if df_clean[c].dtype == \"object\" and c != target_name]\n",
        "num_cols = [c for c in df_clean.columns if c != target_name and np.issubdtype(df_clean[c].dtype, np.number)]\n",
        "\n",
        "for c in cat_cols:\n",
        "    df_clean[c] = df_clean[c].fillna(\"Unknown\")\n",
        "for c in num_cols:\n",
        "    df_clean[c] = df_clean[c].fillna(df_clean[c].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zbp9FGOPP7UI"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to fix this issue and its impacts\n",
        "data_cleaning_2_explanations = \"\"\"\n",
        "Even though the current dataset shows no missing values, adding a fallback imputation step \n",
        "improves robustness and prevents future errors when new or augmented data include gaps. \n",
        "\n",
        "Categorical features use \"Unknown\" to preserve completeness, \n",
        "while numeric features use median values for stability. \n",
        "\n",
        "This ensures the pipeline remains reliable, reproducible, and ready for real-world data updates.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "51A_eWA0P7W5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_2_explanations</p><h3 font-size: 3em>\n",
              "Even though the current dataset shows no missing values, adding a fallback imputation step \n",
              "improves robustness and prevents future errors when new or augmented data include gaps. \n",
              "\n",
              "Categorical features use \"Unknown\" to preserve completeness, \n",
              "while numeric features use median values for stability. \n",
              "\n",
              "This ensures the pipeline remains reliable, reproducible, and ready for real-world data updates.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_2_explanations', value=data_cleaning_2_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhu0LRMi5PgV"
      },
      "source": [
        "### B.3 Fixing Ratio caps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "eJh1KWoF5Qze"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    12500.000000\n",
              "mean        32.289001\n",
              "std          5.119387\n",
              "min         20.880082\n",
              "25%         28.010949\n",
              "50%         32.357246\n",
              "75%         36.504832\n",
              "max         48.176599\n",
              "Name: credit_ratio, dtype: float64"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean[\"credit_ratio\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dMKB2aKLLhEk"
      },
      "outputs": [],
      "source": [
        "# credit_ratio from percentage to [0,1]\n",
        "df_clean[\"credit_ratio\"] = (df_clean[\"credit_ratio\"] / 100.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    12500.000000\n",
              "mean         0.322890\n",
              "std          0.051194\n",
              "min          0.208801\n",
              "25%          0.280109\n",
              "50%          0.323572\n",
              "75%          0.365048\n",
              "max          0.481766\n",
              "Name: credit_ratio, dtype: float64"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean[\"credit_ratio\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "HHPbgT_PP_5h"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to fix this issue and its impacts\n",
        "data_cleaning_3_explanations = \"\"\"\n",
        "The credit_ratio was converted from percentage to a 0–1 scale for consistency \n",
        "with other ratio features like dti and emi_to_income. \n",
        "\n",
        "Normalizing this value reduces the effect of large outliers and stabilizes model training, \n",
        "especially for linear and distance-based algorithms. \n",
        "This adjustment improves numerical consistency and helps the model learn balanced feature relationships.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Pr9WS8jbP__p"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_3_explanations</p><h3 font-size: 3em>\n",
              "The credit_ratio was converted from percentage to a 0–1 scale for consistency \n",
              "with other ratio features like dti and emi_to_income. \n",
              "\n",
              "Normalizing this value reduces the effect of large outliers and stabilizes model training, \n",
              "especially for linear and distance-based algorithms. \n",
              "This adjustment improves numerical consistency and helps the model learn balanced feature relationships.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_3_explanations', value=data_cleaning_3_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrxmkcJNLiFs"
      },
      "source": [
        "### B.4 Fixing Unit\n",
        "\n",
        "> You can add more cells related to other issues in this section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "WIL-U_qlLiMJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    12500.000000\n",
              "mean       221.158240\n",
              "std         99.702928\n",
              "min          2.000000\n",
              "25%        144.750000\n",
              "50%        219.000000\n",
              "75%        302.000000\n",
              "max        404.000000\n",
              "Name: count_credit_history_years, dtype: float64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "df_clean[\"count_credit_history_years\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "85n-2YC-_c2n"
      },
      "outputs": [],
      "source": [
        "# 信用历史：把“count_credit_history_years（实为月）”校正成年，并删除原列\n",
        "df_clean[\"credit_history_years\"] = (df_clean[\"count_credit_history_years\"] / 12.0).clip(lower=0)\n",
        "df_clean.drop(columns=[\"count_credit_history_years\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    12500.000000\n",
              "mean        18.429853\n",
              "std          8.308577\n",
              "min          0.166667\n",
              "25%         12.062500\n",
              "50%         18.250000\n",
              "75%         25.166667\n",
              "max         33.666667\n",
              "Name: credit_history_years, dtype: float64"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean[\"credit_history_years\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "octqRnEF_dAo"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to fix this issue and its impacts\n",
        "data_cleaning_4_explanations = \"\"\"\n",
        "The original count_credit_history_years values were unrealistically high, \n",
        "suggesting the data was recorded in months. \n",
        "Converting it to years by dividing by 12 corrects the unit error and aligns it with business meaning. \n",
        "The original column was removed to avoid redundancy and multicollinearity. \n",
        "This fix improves data accuracy and ensures consistent interpretation of credit history length \n",
        "across models.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "WEy5hyRy_dQe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_4_explanations</p><h3 font-size: 3em>\n",
              "The original count_credit_history_years values were unrealistically high, \n",
              "suggesting the data was recorded in months. \n",
              "Converting it to years by dividing by 12 corrects the unit error and aligns it with business meaning. \n",
              "The original column was removed to avoid redundancy and multicollinearity. \n",
              "This fix improves data accuracy and ensures consistent interpretation of credit history length \n",
              "across models.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_4_explanations', value=data_cleaning_4_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jsWz-z5-XS"
      },
      "source": [
        "---\n",
        "## C. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "viLWliu76Fm6"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "# Create copy of datasets\n",
        "\n",
        "try:\n",
        "  df_eng = df_clean.copy()\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imwl7ISs6O0t"
      },
      "source": [
        "### C.1 New Feature \"dti\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "t5RVBQKW6mJj"
      },
      "outputs": [],
      "source": [
        "eps = 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "F1u712T5Lr04"
      },
      "outputs": [],
      "source": [
        "df_eng[\"dti\"] = (df_eng[\"outstanding_debt\"].clip(lower=0) * 12.0) / (df_eng[\"annual_income\"].abs() + eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "M-kYSZDfQFks"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "feature_engineering_1_explanations = \"\"\"\n",
        "The debt-to-income (DTI) ratio, calculated as (outstanding_debt * 12) / annual_income, \n",
        "measures a customer’s repayment burden relative to income. \n",
        "It captures financial stress and is often effective in distinguishing between \n",
        "Good, Standard, and Poor credit ratings. \n",
        "Adding this feature improves model interpretability and can replace raw debt values \n",
        "to reduce collinearity while keeping strong predictive power.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "25d_SMvaQFr1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_1_explanations</p><h3 font-size: 3em>\n",
              "The debt-to-income (DTI) ratio, calculated as (outstanding_debt * 12) / annual_income, \n",
              "measures a customer’s repayment burden relative to income. \n",
              "It captures financial stress and is often effective in distinguishing between \n",
              "Good, Standard, and Poor credit ratings. \n",
              "Adding this feature improves model interpretability and can replace raw debt values \n",
              "to reduce collinearity while keeping strong predictive power.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_1_explanations', value=feature_engineering_1_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxCnW3C6zJj"
      },
      "source": [
        "### C.2 New Feature \"emi_to_income\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eng[\"emi_to_income\"] = (df_eng[\"monthly_emi_payment\"] * 12.0) / (df_eng[\"annual_income\"].abs() + eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "feature_engineering_2_explanations = \"\"\"\n",
        "The emi_to_income ratio, calculated as (monthly_emi_payment * 12) / annual_income, \n",
        "shows how much of a customer’s income is used for loan repayments. \n",
        "A higher value indicates tighter cash flow and higher default risk. \n",
        "This feature complements DTI by providing another view of repayment burden, \n",
        "helping the model better capture financial stress and predict credit rating changes.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_2_explanations</p><h3 font-size: 3em>\n",
              "The emi_to_income ratio, calculated as (monthly_emi_payment * 12) / annual_income, \n",
              "shows how much of a customer’s income is used for loan repayments. \n",
              "A higher value indicates tighter cash flow and higher default risk. \n",
              "This feature complements DTI by providing another view of repayment burden, \n",
              "helping the model better capture financial stress and predict credit rating changes.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_2_explanations', value=feature_engineering_2_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.3 New Feature Log1p for skewed amounts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "HcSkZYwbLuqy"
      },
      "outputs": [],
      "source": [
        "for c in [\"annual_income\",\"outstanding_debt\",\"monthly_emi_payment\",\"_monthly_invested_amount\",\"monthly_balance\"]:\n",
        "    df_eng[f\"log1p__{c}\"] = np.log1p(df_eng[c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "UVtR91G3QLVk"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "feature_engineering_3_explanations = \"\"\"\n",
        "Long-tailed monetary variables such as income, debt, and balance were log-transformed \n",
        "using log1p to reduce skewness and stabilize variance. \n",
        "This transformation makes feature distributions more regular and improves linear separability. \n",
        "It helps models learn smoother relationships, reduces the impact of extreme values, \n",
        "and enhances overall training stability.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "PMH2cyXzQLYr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_3_explanations</p><h3 font-size: 3em>\n",
              "Long-tailed monetary variables such as income, debt, and balance were log-transformed \n",
              "using log1p to reduce skewness and stabilize variance. \n",
              "This transformation makes feature distributions more regular and improves linear separability. \n",
              "It helps models learn smoother relationships, reduces the impact of extreme values, \n",
              "and enhances overall training stability.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_3_explanations', value=feature_engineering_3_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWF4jvXb62kU"
      },
      "source": [
        "### C.4 New Feature Loan-type low-dimensional signals\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "9iuqF2MBLwKN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loan type columns: ['last_9_loan_type', 'last_8_loan_type', 'last_7_loan_type', 'last_6_loan_type', 'last_5_loan_type', 'last_4_loan_type', 'last_3_loan_type', 'last_2_loan_type', 'last_1_loan_type']\n",
            "Unique loan types: 10\n",
            "\n",
            "Loan type counts:\n",
            "No Loan                    68339\n",
            "Payday Loan                 5071\n",
            "Credit-Builder Loan         5055\n",
            "Not Specified               4952\n",
            "Home Equity Loan            4888\n",
            "Student Loan                4871\n",
            "Mortgage Loan               4867\n",
            "Personal Loan               4861\n",
            "Debt Consolidation Loan     4847\n",
            "Auto Loan                   4749\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# find all last_x_loan_type columns(last_ start and _loan_type tail）\n",
        "loan_cols = [c for c in df.columns if c.startswith(\"last_\") and c.endswith(\"_loan_type\")]\n",
        "print(\"Loan type columns:\", loan_cols)\n",
        "\n",
        "# merge those last_x_loan_type columns\n",
        "loan_types_all = pd.Series(df[loan_cols].values.ravel())\n",
        "\n",
        "# fix missing values(Robustness)\n",
        "loan_types_all = loan_types_all.dropna()\n",
        "\n",
        "# counts number of loan type\n",
        "loan_type_counts = loan_types_all.value_counts()\n",
        "\n",
        "# print\n",
        "print(\"Unique loan types:\", loan_type_counts.shape[0])\n",
        "print(\"\\nLoan type counts:\")\n",
        "print(loan_type_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Payday loan\n",
        "df_eng[\"flag_payday_recent\"] = (\n",
        "    df_eng[loan_cols].apply(lambda row: int(any(str(v) == \"Payday Loan\" for v in row)), axis=1)\n",
        ")\n",
        "\n",
        "# Not all 'No Loan'\n",
        "df_eng[\"flag_has_any_loan\"] = (\n",
        "    df_eng[loan_cols].apply(lambda row: int(any(str(v) != \"No Loan\" for v in row)), axis=1)\n",
        ")\n",
        "\n",
        "# Diversity of loan types\n",
        "def _diversity(xs):\n",
        "    s = set([str(v) for v in xs if str(v) != \"No Loan\"])\n",
        "    return len(s)\n",
        "df_eng[\"loan_type_diversity\"] = df_eng[loan_cols].apply(_diversity, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ai9-L0dnQPvV"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "feature_engineering_4_explanations = \"\"\"\n",
        "Instead of one-hot encoding nine loan-type columns, we created three low-dimensional signals: whether the customer has any loan, whether a Payday Loan appears, and the diversity of loan types. These features capture key behavioral information while avoiding feature explosion and overfitting. This approach keeps the data compact, improves interpretability, and preserves essential credit risk signals for modeling.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "okaLOh0SQP1V"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_4_explanations</p><h3 font-size: 3em>\n",
              "Instead of one-hot encoding nine loan-type columns, we created three low-dimensional signals: whether the customer has any loan, whether a Payday Loan appears, and the diversity of loan types. These features capture key behavioral information while avoiding feature explosion and overfitting. This approach keeps the data compact, improves interpretability, and preserves essential credit risk signals for modeling.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_4_explanations', value=feature_engineering_4_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.5 Fixing Multicollinearity (Remove Original Features)\n",
        "\n",
        "> You can add more cells related to new features in this section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped redundant raw features: ['annual_income', 'outstanding_debt', 'monthly_emi_payment', '_monthly_invested_amount', 'monthly_balance', 'last_9_loan_type', 'last_8_loan_type', 'last_7_loan_type', 'last_6_loan_type', 'last_5_loan_type', 'last_4_loan_type', 'last_3_loan_type', 'last_2_loan_type', 'last_1_loan_type']\n",
            "Index(['age', 'birth_country', 'occupation', 'count_bank_accounts',\n",
            "       'count_credit_cards', 'loans_count', 'avg_days_past_due',\n",
            "       'count_delayed_payment', 'count_credit_inquiries', 'credit_ratio',\n",
            "       'min_amount_payment', 'payment_behaviour', 'cc_interest_rate',\n",
            "       'credit_limit_change', 'credit_mix', 'gender', 'credit_rating',\n",
            "       'credit_history_years', 'dti', 'emi_to_income', 'log1p__annual_income',\n",
            "       'log1p__outstanding_debt', 'log1p__monthly_emi_payment',\n",
            "       'log1p___monthly_invested_amount', 'log1p__monthly_balance',\n",
            "       'flag_payday_recent', 'flag_has_any_loan', 'loan_type_diversity'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Necessary drops: avoid multicollinearity and feature explosion\n",
        "drop_cols = [\n",
        "    \"annual_income\",             # replaced by log1p__annual_income, dti, and emi_to_income\n",
        "    \"outstanding_debt\",          # captured in dti\n",
        "    \"monthly_emi_payment\",       # captured in emi_to_income\n",
        "    \"_monthly_invested_amount\",  # replaced by log1p__ version\n",
        "    \"monthly_balance\",           # replaced by log1p__ version\n",
        "] + loan_cols  # all original last_k_loan_type columns replaced by low-dimensional signals\n",
        "\n",
        "df_eng.drop(columns=[c for c in drop_cols if c in df_eng.columns], inplace=True)\n",
        "print(\"Dropped redundant raw features:\", drop_cols)\n",
        "print(df_eng.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "GCgD5TwA_NrH"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "feature_engineering_5_explanations = \"\"\"\n",
        "Removing redundant raw variables helps prevent multicollinearity and unnecessary model complexity. The dropped features were already represented by transformed or derived variables such as dti, emi_to_income, and log1p__ versions, ensuring no information loss. Deleting the original loan-type columns also avoids feature explosion from one-hot encoding. This step keeps the dataset compact, stable, and more interpretable for modeling.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "q-H6x7Tf_N0G"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_5_explanations</p><h3 font-size: 3em>\n",
              "Removing redundant raw variables helps prevent multicollinearity and unnecessary model complexity. The dropped features were already represented by transformed or derived variables such as dti, emi_to_income, and log1p__ versions, ensuring no information loss. Deleting the original loan-type columns also avoids feature explosion from one-hot encoding. This step keeps the dataset compact, stable, and more interpretable for modeling.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_5_explanations', value=feature_engineering_5_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0S5LSAcjkvP"
      },
      "source": [
        "---\n",
        "## D. Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOCutkG6k3GQ"
      },
      "source": [
        "### D.1 Split Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "UmPVLaNulC1s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (8750, 27) (1875, 27) (1875, 27) (8750,) (1875,) (1875,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = df_eng.drop(columns=[target_name])\n",
        "y = df_eng[target_name].copy()\n",
        "\n",
        "X_train_raw, X_temp_raw, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y  # 70% train\n",
        ")\n",
        "X_val_raw, X_test_raw, y_val, y_test = train_test_split(\n",
        "    X_temp_raw, y_temp, test_size=0.50, random_state=42, stratify=y_temp  # 15%/15%\n",
        ")\n",
        "\n",
        "print(\"Shapes:\",\n",
        "      X_train_raw.shape, X_val_raw.shape, X_test_raw.shape,\n",
        "      y_train.shape, y_val.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "gZFFgktrlC7k"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on what is the best strategy to use for data splitting for this dataset\n",
        "data_splitting_explanations = \"\"\"\n",
        "A stratified 70/15/15 split was used to keep the class distribution stable across train, validation, and test sets. This approach provides a fair balance between training volume and reliable evaluation. The validation set offers a consistent baseline for simple models, while K-Fold cross-validation can be applied within the training set for more complex tuning. Splitting before encoding or scaling prevents data leakage, ensuring that all transformations are fit only on the training data. This strategy supports both comparability and robustness in model evaluation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "nY914h0klDAi"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">data_splitting_explanations</p><h3 font-size: 3em>\n",
              "A stratified 70/15/15 split was used to keep the class distribution stable across train, validation, and test sets. This approach provides a fair balance between training volume and reliable evaluation. The validation set offers a consistent baseline for simple models, while K-Fold cross-validation can be applied within the training set for more complex tuning. Splitting before encoding or scaling prevents data leakage, ensuring that all transformations are fit only on the training data. This strategy supports both comparability and robustness in model evaluation.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_splitting_explanations', value=data_splitting_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKqt6BN6csNC"
      },
      "source": [
        "### D.2 Data Transformation — OHE + Standardize (Fit by train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "7PnGwsy2hez4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>birth_country_AU</th>\n",
              "      <th>birth_country_BR</th>\n",
              "      <th>birth_country_CA</th>\n",
              "      <th>birth_country_CO</th>\n",
              "      <th>birth_country_FR</th>\n",
              "      <th>birth_country_IE</th>\n",
              "      <th>birth_country_IN</th>\n",
              "      <th>birth_country_IT</th>\n",
              "      <th>birth_country_NZ</th>\n",
              "      <th>birth_country_PH</th>\n",
              "      <th>...</th>\n",
              "      <th>dti</th>\n",
              "      <th>emi_to_income</th>\n",
              "      <th>log1p__annual_income</th>\n",
              "      <th>log1p__outstanding_debt</th>\n",
              "      <th>log1p__monthly_emi_payment</th>\n",
              "      <th>log1p___monthly_invested_amount</th>\n",
              "      <th>log1p__monthly_balance</th>\n",
              "      <th>flag_payday_recent</th>\n",
              "      <th>flag_has_any_loan</th>\n",
              "      <th>loan_type_diversity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2987</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.596776</td>\n",
              "      <td>-0.973657</td>\n",
              "      <td>-0.206441</td>\n",
              "      <td>-1.104840</td>\n",
              "      <td>-0.559860</td>\n",
              "      <td>0.236443</td>\n",
              "      <td>-0.026572</td>\n",
              "      <td>-0.691585</td>\n",
              "      <td>0.359008</td>\n",
              "      <td>-1.031835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9461</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.185613</td>\n",
              "      <td>-0.027072</td>\n",
              "      <td>-0.441362</td>\n",
              "      <td>0.212834</td>\n",
              "      <td>0.200585</td>\n",
              "      <td>-0.599857</td>\n",
              "      <td>0.051902</td>\n",
              "      <td>-0.691585</td>\n",
              "      <td>0.359008</td>\n",
              "      <td>0.667498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2909</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278885</td>\n",
              "      <td>-0.693435</td>\n",
              "      <td>-1.031888</td>\n",
              "      <td>0.377586</td>\n",
              "      <td>-0.527591</td>\n",
              "      <td>-1.599893</td>\n",
              "      <td>0.073845</td>\n",
              "      <td>-0.691585</td>\n",
              "      <td>0.359008</td>\n",
              "      <td>-0.465391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 62 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      birth_country_AU  birth_country_BR  birth_country_CA  birth_country_CO  \\\n",
              "2987               1.0               0.0               0.0               0.0   \n",
              "9461               1.0               0.0               0.0               0.0   \n",
              "2909               1.0               0.0               0.0               0.0   \n",
              "\n",
              "      birth_country_FR  birth_country_IE  birth_country_IN  birth_country_IT  \\\n",
              "2987               0.0               0.0               0.0               0.0   \n",
              "9461               0.0               0.0               0.0               0.0   \n",
              "2909               0.0               0.0               0.0               0.0   \n",
              "\n",
              "      birth_country_NZ  birth_country_PH  ...       dti  emi_to_income  \\\n",
              "2987               0.0               0.0  ... -0.596776      -0.973657   \n",
              "9461               0.0               0.0  ... -0.185613      -0.027072   \n",
              "2909               0.0               0.0  ...  0.278885      -0.693435   \n",
              "\n",
              "      log1p__annual_income  log1p__outstanding_debt  \\\n",
              "2987             -0.206441                -1.104840   \n",
              "9461             -0.441362                 0.212834   \n",
              "2909             -1.031888                 0.377586   \n",
              "\n",
              "      log1p__monthly_emi_payment  log1p___monthly_invested_amount  \\\n",
              "2987                   -0.559860                         0.236443   \n",
              "9461                    0.200585                        -0.599857   \n",
              "2909                   -0.527591                        -1.599893   \n",
              "\n",
              "      log1p__monthly_balance  flag_payday_recent  flag_has_any_loan  \\\n",
              "2987               -0.026572           -0.691585           0.359008   \n",
              "9461                0.051902           -0.691585           0.359008   \n",
              "2909                0.073845           -0.691585           0.359008   \n",
              "\n",
              "      loan_type_diversity  \n",
              "2987            -1.031835  \n",
              "9461             0.667498  \n",
              "2909            -0.465391  \n",
              "\n",
              "[3 rows x 62 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Categorical → One-Hot Encoding (ignore unknown categories)\n",
        "categorical_cols = [c for c in X_train_raw.columns if X_train_raw[c].dtype == \"object\"]\n",
        "numeric_cols = [c for c in X_train_raw.columns if c not in categorical_cols]\n",
        "\n",
        "# Define encoders and scalers\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "\n",
        "# Combine categorical and numerical preprocessing\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", ohe, categorical_cols),\n",
        "        (\"num\", scaler, numeric_cols),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "# Fit on train only to avoid data leakage\n",
        "X_train = preprocess.fit_transform(X_train_raw)\n",
        "X_val   = preprocess.transform(X_val_raw)\n",
        "X_test  = preprocess.transform(X_test_raw)\n",
        "\n",
        "# Restore column names\n",
        "ohe_names = list(preprocess.named_transformers_[\"cat\"].get_feature_names_out(categorical_cols)) if categorical_cols else []\n",
        "all_names = ohe_names + numeric_cols\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=all_names, index=X_train_raw.index)\n",
        "X_val   = pd.DataFrame(X_val,   columns=all_names, index=X_val_raw.index)\n",
        "X_test  = pd.DataFrame(X_test,  columns=all_names, index=X_test_raw.index)\n",
        "\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_val   = y_val.reset_index(drop=True)\n",
        "y_test  = y_test.reset_index(drop=True)\n",
        "\n",
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "or7RgXjwQaAo"
      },
      "outputs": [],
      "source": [
        "# Provide some explanations on why you believe it is important to perform this data transformation and its impacts\n",
        "data_transformation_1_explanations = \"\"\"\n",
        "Categorical variables were one-hot encoded to make them usable by both tree-based and linear models, while numerical features were standardized to improve model stability and comparability. The transformation was fitted only on the training set to prevent information leakage. This approach enhances performance for algorithms sensitive to feature scale, such as Logistic Regression and SVM. Keeping derived features like dti and emi_to_income while removing raw outstanding_debt reduces multicollinearity but preserves financial signal strength.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "f7EzJD6JQaF8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color:grey\">data_transformation_1_explanations</p><h3 font-size: 3em>\n",
              "Categorical variables were one-hot encoded to make them usable by both tree-based and linear models, while numerical features were standardized to improve model stability and comparability. The transformation was fitted only on the training set to prevent information leakage. This approach enhances performance for algorithms sensitive to feature scale, such as Logistic Regression and SVM. Keeping derived features like dti and emi_to_income while removing raw outstanding_debt reduces multicollinearity but preserves financial signal strength.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_transformation_1_explanations', value=data_transformation_1_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0CJolMhdmLf"
      },
      "source": [
        "---\n",
        "## E. Save Datasets\n",
        "\n",
        "> Do not change this code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "hwIgKOsGdrf3"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "\n",
        "try:\n",
        "  X_train.to_csv(at.folder_path / 'X_train.csv', index=False)\n",
        "  y_train.to_csv(at.folder_path / 'y_train.csv', index=False)\n",
        "\n",
        "  X_val.to_csv(at.folder_path / 'X_val.csv', index=False)\n",
        "  y_val.to_csv(at.folder_path / 'y_val.csv', index=False)\n",
        "\n",
        "  X_test.to_csv(at.folder_path / 'X_test.csv', index=False)\n",
        "  y_test.to_csv(at.folder_path / 'y_test.csv', index=False)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
